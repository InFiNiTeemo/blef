{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-24T07:29:59.311472Z",
     "iopub.status.busy": "2022-05-24T07:29:59.311164Z",
     "iopub.status.idle": "2022-05-24T07:32:18.391358Z",
     "shell.execute_reply": "2022-05-24T07:32:18.390055Z",
     "shell.execute_reply.started": "2022-05-24T07:29:59.311375Z"
    }
   },
   "outputs": [],
   "source": [
    "## setup\n",
    "## TODO: move all under bird2022wheels\n",
    "!pip install ../input/birds-inference-pip-wheels/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl ../input/birds-inference-pip-wheels/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install ../input/birds-inference-pip-wheels/audiomentations-0.16.0-py3-none-any.whl --no-index --no-deps\n",
    "!pip install ../input/birds-inference-pip-wheels/torchlibrosa-0.0.9-py3-none-any.whl --no-index --no-deps\n",
    "!pip install ../input/birds2022wheels/nnAudio-0.3.1-py3-none-any.whl\n",
    "!cp -r ../input/timmlatest ../working/timmlatest\n",
    "!pip install -U ../working/timmlatest\n",
    "!rm -rf ../working/timmlatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:18.395054Z",
     "iopub.status.busy": "2022-05-24T07:32:18.394781Z",
     "iopub.status.idle": "2022-05-24T07:32:18.403859Z",
     "shell.execute_reply": "2022-05-24T07:32:18.402778Z",
     "shell.execute_reply.started": "2022-05-24T07:32:18.395017Z"
    }
   },
   "outputs": [],
   "source": [
    "## https://github.com/Selimonder/birdclef2022/\n",
    "import os, sys, glob, math\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "github_folder = \".\"\n",
    "sys.path.append(github_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:18.439623Z",
     "iopub.status.busy": "2022-05-24T07:32:18.439152Z",
     "iopub.status.idle": "2022-05-24T07:32:26.893812Z",
     "shell.execute_reply": "2022-05-24T07:32:26.889825Z",
     "shell.execute_reply.started": "2022-05-24T07:32:18.439581Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gc\n",
    "import re\n",
    "import torch\n",
    "import librosa\n",
    "import argparse, warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "\n",
    "import zoo\n",
    "from training.config import load_config\n",
    "from training.datasets import BirdDatasetOOF\n",
    "\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:26.898111Z",
     "iopub.status.busy": "2022-05-24T07:32:26.897132Z",
     "iopub.status.idle": "2022-05-24T07:32:36.914216Z",
     "shell.execute_reply": "2022-05-24T07:32:36.913499Z",
     "shell.execute_reply.started": "2022-05-24T07:32:26.898067Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(conf_path: str, weights_path: str, prefix: str, suffix: str, fold: int, to_device: bool = True, is_test:bool = False):\n",
    "    conf = load_config(conf_path)\n",
    "    conf['encoder_params']['pretrained'] = False\n",
    "    \n",
    "    snapshot_name = \"{}{}_{}_{}_{}\".format(prefix, conf[\"network\"], conf[\"encoder_params\"][\"encoder\"], fold, suffix)\n",
    "    weights_dir = weights_path\n",
    "    weights_path = os.path.join(weights_path, snapshot_name)\n",
    "    \n",
    "    def test_model():\n",
    "        model_names = ['SED', 'TimmClassifier_v1', 'TimmClassifier_v2', 'TimmClassifier2021', 'TimmClassifier',\n",
    "                       'SEDTrainableFFT', 'C1C2', 'TimmClassifierSplitCrop_v1']\n",
    "        print(model_names)\n",
    "        snapshot_name = \"pretrain_TimmClassifier_eca_nfnet_l0_0_last\"#\"pretrained_eca_nfnet_l0.pth\"# \"pretrain_TimmClassifier_eca_nfnet_l0_0_last\"\n",
    "        weights_path = os.path.join(weights_dir, snapshot_name)   \n",
    "        \n",
    "        raw_conf_model = conf[\"network\"]\n",
    "        for model_name in model_names:\n",
    "            try:\n",
    "                print(\"\\n\\n => current model: \", model_name)\n",
    "                conf[\"network\"] = model_name\n",
    "                load_model(weights_path)\n",
    "            except Exception as e:\n",
    "                print(f\"model not found\", e)\n",
    "                continue\n",
    "            print(\"success!\")\n",
    "        conf[\"network\"] = raw_conf_model\n",
    "    \n",
    "    def load_model(weights_path):\n",
    "        print(weights_path)\n",
    "        model = zoo.__dict__[conf[\"network\"]](**conf[\"encoder_params\"])\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        print(\"=> loading checkpoint '{}''\".format(weights_path))\n",
    "        checkpoint = torch.load(weights_path, map_location=\"cpu\")\n",
    "        print(\"epoch\", checkpoint[\"epoch\"])\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        model.eval()\n",
    "        if to_device: model.cuda()\n",
    "        return model\n",
    "    \n",
    "    if is_test:\n",
    "        test_model()\n",
    "    else:\n",
    "        return load_model(weights_path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model: torch.nn.Module, weight_path):\n",
    "    checkpoint_path = weight_path\n",
    "    if not checkpoint_path:\n",
    "        return\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(checkpoint_path))\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        print(checkpoint.keys())\n",
    "        state_dict_name = \"state_dict\"\n",
    "        if state_dict_name not in checkpoint:\n",
    "            state_dict_name = \"model\"\n",
    "        if state_dict_name in checkpoint:\n",
    "            conflicts = 0\n",
    "            state_dict = checkpoint[state_dict_name]\n",
    "            # print(\"state_dict:\", state_dict.keys())\n",
    "            # state_dict = {re.sub(\"^module.\", \"\", k): w for k, w in state_dict.items()}\n",
    "            # print(\"state_dict:\", state_dict.keys())\n",
    "            orig_state_dict = model.state_dict()\n",
    "            # print(\"orig_state_dict\", orig_state_dict.keys())\n",
    "            mismatched_keys = []\n",
    "            for k, v in state_dict.items():\n",
    "                ori_size = orig_state_dict[k].size() if k in orig_state_dict else None\n",
    "                if v.size() != ori_size:\n",
    "                    conflicts += 1\n",
    "                    # print(\"SKIPPING!!! Shape of {} changed from {} to {}\".format(k, v.size(), ori_size))\n",
    "                    mismatched_keys.append(k)\n",
    "            for k in mismatched_keys:\n",
    "                del state_dict[k]\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "            print(\"=> Not loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(checkpoint_path, checkpoint['epoch']))\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(checkpoint_path))\n",
    "    print(\"conflicts: \", conflicts)\n",
    "    return conflicts\n",
    "    \n",
    "def load_model_v1(conf_path: str, weights_path: str, prefix: str, suffix: str, fold: int, to_device: bool = True, is_test:bool = False):\n",
    "    conf = load_config(conf_path)\n",
    "    conf['encoder_params']['pretrained'] = False\n",
    "    \n",
    "    snapshot_name = \"{}{}_{}_{}_{}\".format(prefix, conf[\"network\"], conf[\"encoder_params\"][\"encoder\"], fold, suffix)\n",
    "    weights_dir = weights_path\n",
    "    weights_path = os.path.join(weights_path, snapshot_name)\n",
    "    \n",
    "    def test_model():\n",
    "        model_names = ['SED', 'TimmClassifier_v1', 'TimmClassifier_v2', 'TimmClassifier2021', 'TimmClassifier',\n",
    "                       'SEDTrainableFFT', 'C1C2', 'TimmClassifierSplitCrop_v1']\n",
    "        print(model_names)\n",
    "        snapshot_name = \"pretrained_eca_nfnet_l0.pth\" # \"pretrain_TimmClassifier_eca_nfnet_l0_0_last\"#\"pretrained_eca_nfnet_l0.pth\"# \"pretrain_TimmClassifier_eca_nfnet_l0_0_last\"\n",
    "        weights_path = os.path.join(weights_dir, snapshot_name)   \n",
    "        \n",
    "        raw_conf_model = conf[\"network\"]\n",
    "        mx, res = 1e5, \"\"\n",
    "        for model_name in model_names:\n",
    "            try:\n",
    "                print(\"\\n\\n => current model: \", model_name)\n",
    "                conf[\"network\"] = model_name\n",
    "                c = load_model(weights_path)\n",
    "                if c < mx:\n",
    "                    mx = c\n",
    "                    res = model_name\n",
    "            except Exception as e:\n",
    "                print(f\"model not found\", e)\n",
    "                continue\n",
    "            print(\"success!\")\n",
    "        conf[\"network\"] = raw_conf_model\n",
    "        print(\"\\n=> best fit:\", res, \" conflicts:\", mx)\n",
    "    \n",
    "    def load_model(weights_path):\n",
    "        print(weights_path)\n",
    "        model = zoo.__dict__[conf[\"network\"]](**conf[\"encoder_params\"])\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        return load_checkpoint(model, weights_path)\n",
    "    \n",
    "    if is_test:\n",
    "        test_model()\n",
    "    else:\n",
    "        return load_model(weights_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SED', 'TimmClassifier_v1', 'TimmClassifier_v2', 'TimmClassifier2021', 'TimmClassifier', 'SEDTrainableFFT', 'C1C2', 'TimmClassifierSplitCrop_v1']\n",
      "\n",
      "\n",
      " => current model:  SED\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing SED model...\n",
      "model not found NormFreeNet.__init__() got an unexpected keyword argument 'duration'\n",
      "\n",
      "\n",
      " => current model:  TimmClassifier_v1\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth'\n",
      "odict_keys(['stem.conv1.weight', 'stem.conv1.bias', 'stem.conv1.gain', 'stem.conv2.weight', 'stem.conv2.bias', 'stem.conv2.gain', 'stem.conv3.weight', 'stem.conv3.bias', 'stem.conv3.gain', 'stem.conv4.weight', 'stem.conv4.bias', 'stem.conv4.gain', 'stages.0.0.downsample.conv.weight', 'stages.0.0.downsample.conv.bias', 'stages.0.0.downsample.conv.gain', 'stages.0.0.conv1.weight', 'stages.0.0.conv1.bias', 'stages.0.0.conv1.gain', 'stages.0.0.conv2.weight', 'stages.0.0.conv2.bias', 'stages.0.0.conv2.gain', 'stages.0.0.conv2b.weight', 'stages.0.0.conv2b.bias', 'stages.0.0.conv2b.gain', 'stages.0.0.conv3.weight', 'stages.0.0.conv3.bias', 'stages.0.0.conv3.gain', 'stages.0.0.attn_last.conv.weight', 'stages.1.0.downsample.conv.weight', 'stages.1.0.downsample.conv.bias', 'stages.1.0.downsample.conv.gain', 'stages.1.0.conv1.weight', 'stages.1.0.conv1.bias', 'stages.1.0.conv1.gain', 'stages.1.0.conv2.weight', 'stages.1.0.conv2.bias', 'stages.1.0.conv2.gain', 'stages.1.0.conv2b.weight', 'stages.1.0.conv2b.bias', 'stages.1.0.conv2b.gain', 'stages.1.0.conv3.weight', 'stages.1.0.conv3.bias', 'stages.1.0.conv3.gain', 'stages.1.0.attn_last.conv.weight', 'stages.1.1.conv1.weight', 'stages.1.1.conv1.bias', 'stages.1.1.conv1.gain', 'stages.1.1.conv2.weight', 'stages.1.1.conv2.bias', 'stages.1.1.conv2.gain', 'stages.1.1.conv2b.weight', 'stages.1.1.conv2b.bias', 'stages.1.1.conv2b.gain', 'stages.1.1.conv3.weight', 'stages.1.1.conv3.bias', 'stages.1.1.conv3.gain', 'stages.1.1.attn_last.conv.weight', 'stages.2.0.downsample.conv.weight', 'stages.2.0.downsample.conv.bias', 'stages.2.0.downsample.conv.gain', 'stages.2.0.conv1.weight', 'stages.2.0.conv1.bias', 'stages.2.0.conv1.gain', 'stages.2.0.conv2.weight', 'stages.2.0.conv2.bias', 'stages.2.0.conv2.gain', 'stages.2.0.conv2b.weight', 'stages.2.0.conv2b.bias', 'stages.2.0.conv2b.gain', 'stages.2.0.conv3.weight', 'stages.2.0.conv3.bias', 'stages.2.0.conv3.gain', 'stages.2.0.attn_last.conv.weight', 'stages.2.1.conv1.weight', 'stages.2.1.conv1.bias', 'stages.2.1.conv1.gain', 'stages.2.1.conv2.weight', 'stages.2.1.conv2.bias', 'stages.2.1.conv2.gain', 'stages.2.1.conv2b.weight', 'stages.2.1.conv2b.bias', 'stages.2.1.conv2b.gain', 'stages.2.1.conv3.weight', 'stages.2.1.conv3.bias', 'stages.2.1.conv3.gain', 'stages.2.1.attn_last.conv.weight', 'stages.2.2.conv1.weight', 'stages.2.2.conv1.bias', 'stages.2.2.conv1.gain', 'stages.2.2.conv2.weight', 'stages.2.2.conv2.bias', 'stages.2.2.conv2.gain', 'stages.2.2.conv2b.weight', 'stages.2.2.conv2b.bias', 'stages.2.2.conv2b.gain', 'stages.2.2.conv3.weight', 'stages.2.2.conv3.bias', 'stages.2.2.conv3.gain', 'stages.2.2.attn_last.conv.weight', 'stages.2.3.conv1.weight', 'stages.2.3.conv1.bias', 'stages.2.3.conv1.gain', 'stages.2.3.conv2.weight', 'stages.2.3.conv2.bias', 'stages.2.3.conv2.gain', 'stages.2.3.conv2b.weight', 'stages.2.3.conv2b.bias', 'stages.2.3.conv2b.gain', 'stages.2.3.conv3.weight', 'stages.2.3.conv3.bias', 'stages.2.3.conv3.gain', 'stages.2.3.attn_last.conv.weight', 'stages.2.4.conv1.weight', 'stages.2.4.conv1.bias', 'stages.2.4.conv1.gain', 'stages.2.4.conv2.weight', 'stages.2.4.conv2.bias', 'stages.2.4.conv2.gain', 'stages.2.4.conv2b.weight', 'stages.2.4.conv2b.bias', 'stages.2.4.conv2b.gain', 'stages.2.4.conv3.weight', 'stages.2.4.conv3.bias', 'stages.2.4.conv3.gain', 'stages.2.4.attn_last.conv.weight', 'stages.2.5.conv1.weight', 'stages.2.5.conv1.bias', 'stages.2.5.conv1.gain', 'stages.2.5.conv2.weight', 'stages.2.5.conv2.bias', 'stages.2.5.conv2.gain', 'stages.2.5.conv2b.weight', 'stages.2.5.conv2b.bias', 'stages.2.5.conv2b.gain', 'stages.2.5.conv3.weight', 'stages.2.5.conv3.bias', 'stages.2.5.conv3.gain', 'stages.2.5.attn_last.conv.weight', 'stages.3.0.downsample.conv.weight', 'stages.3.0.downsample.conv.bias', 'stages.3.0.downsample.conv.gain', 'stages.3.0.conv1.weight', 'stages.3.0.conv1.bias', 'stages.3.0.conv1.gain', 'stages.3.0.conv2.weight', 'stages.3.0.conv2.bias', 'stages.3.0.conv2.gain', 'stages.3.0.conv2b.weight', 'stages.3.0.conv2b.bias', 'stages.3.0.conv2b.gain', 'stages.3.0.conv3.weight', 'stages.3.0.conv3.bias', 'stages.3.0.conv3.gain', 'stages.3.0.attn_last.conv.weight', 'stages.3.1.conv1.weight', 'stages.3.1.conv1.bias', 'stages.3.1.conv1.gain', 'stages.3.1.conv2.weight', 'stages.3.1.conv2.bias', 'stages.3.1.conv2.gain', 'stages.3.1.conv2b.weight', 'stages.3.1.conv2b.bias', 'stages.3.1.conv2b.gain', 'stages.3.1.conv3.weight', 'stages.3.1.conv3.bias', 'stages.3.1.conv3.gain', 'stages.3.1.attn_last.conv.weight', 'stages.3.2.conv1.weight', 'stages.3.2.conv1.bias', 'stages.3.2.conv1.gain', 'stages.3.2.conv2.weight', 'stages.3.2.conv2.bias', 'stages.3.2.conv2.gain', 'stages.3.2.conv2b.weight', 'stages.3.2.conv2b.bias', 'stages.3.2.conv2b.gain', 'stages.3.2.conv3.weight', 'stages.3.2.conv3.bias', 'stages.3.2.conv3.gain', 'stages.3.2.attn_last.conv.weight', 'final_conv.weight', 'final_conv.bias', 'final_conv.gain'])\n",
      "model not found Error(s) in loading state_dict for DataParallel:\n",
      "\tMissing key(s) in state_dict: \"module.mel_spec.spectrogram.window\", \"module.mel_spec.mel_scale.fb\", \"module.wav2img.0.spectrogram.window\", \"module.wav2img.0.mel_scale.fb\", \"module.encoder.stem_conv1.weight\", \"module.encoder.stem_conv1.bias\", \"module.encoder.stem_conv1.gain\", \"module.encoder.stem_conv2.weight\", \"module.encoder.stem_conv2.bias\", \"module.encoder.stem_conv2.gain\", \"module.encoder.stem_conv3.weight\", \"module.encoder.stem_conv3.bias\", \"module.encoder.stem_conv3.gain\", \"module.encoder.stem_conv4.weight\", \"module.encoder.stem_conv4.bias\", \"module.encoder.stem_conv4.gain\", \"module.encoder.stages_0.0.downsample.conv.weight\", \"module.encoder.stages_0.0.downsample.conv.bias\", \"module.encoder.stages_0.0.downsample.conv.gain\", \"module.encoder.stages_0.0.conv1.weight\", \"module.encoder.stages_0.0.conv1.bias\", \"module.encoder.stages_0.0.conv1.gain\", \"module.encoder.stages_0.0.conv2.weight\", \"module.encoder.stages_0.0.conv2.bias\", \"module.encoder.stages_0.0.conv2.gain\", \"module.encoder.stages_0.0.conv2b.weight\", \"module.encoder.stages_0.0.conv2b.bias\", \"module.encoder.stages_0.0.conv2b.gain\", \"module.encoder.stages_0.0.conv3.weight\", \"module.encoder.stages_0.0.conv3.bias\", \"module.encoder.stages_0.0.conv3.gain\", \"module.encoder.stages_0.0.attn_last.conv.weight\", \"module.encoder.stages_1.0.downsample.conv.weight\", \"module.encoder.stages_1.0.downsample.conv.bias\", \"module.encoder.stages_1.0.downsample.conv.gain\", \"module.encoder.stages_1.0.conv1.weight\", \"module.encoder.stages_1.0.conv1.bias\", \"module.encoder.stages_1.0.conv1.gain\", \"module.encoder.stages_1.0.conv2.weight\", \"module.encoder.stages_1.0.conv2.bias\", \"module.encoder.stages_1.0.conv2.gain\", \"module.encoder.stages_1.0.conv2b.weight\", \"module.encoder.stages_1.0.conv2b.bias\", \"module.encoder.stages_1.0.conv2b.gain\", \"module.encoder.stages_1.0.conv3.weight\", \"module.encoder.stages_1.0.conv3.bias\", \"module.encoder.stages_1.0.conv3.gain\", \"module.encoder.stages_1.0.attn_last.conv.weight\", \"module.encoder.stages_1.1.conv1.weight\", \"module.encoder.stages_1.1.conv1.bias\", \"module.encoder.stages_1.1.conv1.gain\", \"module.encoder.stages_1.1.conv2.weight\", \"module.encoder.stages_1.1.conv2.bias\", \"module.encoder.stages_1.1.conv2.gain\", \"module.encoder.stages_1.1.conv2b.weight\", \"module.encoder.stages_1.1.conv2b.bias\", \"module.encoder.stages_1.1.conv2b.gain\", \"module.encoder.stages_1.1.conv3.weight\", \"module.encoder.stages_1.1.conv3.bias\", \"module.encoder.stages_1.1.conv3.gain\", \"module.encoder.stages_1.1.attn_last.conv.weight\", \"module.encoder.stages_2.0.downsample.conv.weight\", \"module.encoder.stages_2.0.downsample.conv.bias\", \"module.encoder.stages_2.0.downsample.conv.gain\", \"module.encoder.stages_2.0.conv1.weight\", \"module.encoder.stages_2.0.conv1.bias\", \"module.encoder.stages_2.0.conv1.gain\", \"module.encoder.stages_2.0.conv2.weight\", \"module.encoder.stages_2.0.conv2.bias\", \"module.encoder.stages_2.0.conv2.gain\", \"module.encoder.stages_2.0.conv2b.weight\", \"module.encoder.stages_2.0.conv2b.bias\", \"module.encoder.stages_2.0.conv2b.gain\", \"module.encoder.stages_2.0.conv3.weight\", \"module.encoder.stages_2.0.conv3.bias\", \"module.encoder.stages_2.0.conv3.gain\", \"module.encoder.stages_2.0.attn_last.conv.weight\", \"module.encoder.stages_2.1.conv1.weight\", \"module.encoder.stages_2.1.conv1.bias\", \"module.encoder.stages_2.1.conv1.gain\", \"module.encoder.stages_2.1.conv2.weight\", \"module.encoder.stages_2.1.conv2.bias\", \"module.encoder.stages_2.1.conv2.gain\", \"module.encoder.stages_2.1.conv2b.weight\", \"module.encoder.stages_2.1.conv2b.bias\", \"module.encoder.stages_2.1.conv2b.gain\", \"module.encoder.stages_2.1.conv3.weight\", \"module.encoder.stages_2.1.conv3.bias\", \"module.encoder.stages_2.1.conv3.gain\", \"module.encoder.stages_2.1.attn_last.conv.weight\", \"module.encoder.stages_2.2.conv1.weight\", \"module.encoder.stages_2.2.conv1.bias\", \"module.encoder.stages_2.2.conv1.gain\", \"module.encoder.stages_2.2.conv2.weight\", \"module.encoder.stages_2.2.conv2.bias\", \"module.encoder.stages_2.2.conv2.gain\", \"module.encoder.stages_2.2.conv2b.weight\", \"module.encoder.stages_2.2.conv2b.bias\", \"module.encoder.stages_2.2.conv2b.gain\", \"module.encoder.stages_2.2.conv3.weight\", \"module.encoder.stages_2.2.conv3.bias\", \"module.encoder.stages_2.2.conv3.gain\", \"module.encoder.stages_2.2.attn_last.conv.weight\", \"module.encoder.stages_2.3.conv1.weight\", \"module.encoder.stages_2.3.conv1.bias\", \"module.encoder.stages_2.3.conv1.gain\", \"module.encoder.stages_2.3.conv2.weight\", \"module.encoder.stages_2.3.conv2.bias\", \"module.encoder.stages_2.3.conv2.gain\", \"module.encoder.stages_2.3.conv2b.weight\", \"module.encoder.stages_2.3.conv2b.bias\", \"module.encoder.stages_2.3.conv2b.gain\", \"module.encoder.stages_2.3.conv3.weight\", \"module.encoder.stages_2.3.conv3.bias\", \"module.encoder.stages_2.3.conv3.gain\", \"module.encoder.stages_2.3.attn_last.conv.weight\", \"module.encoder.stages_2.4.conv1.weight\", \"module.encoder.stages_2.4.conv1.bias\", \"module.encoder.stages_2.4.conv1.gain\", \"module.encoder.stages_2.4.conv2.weight\", \"module.encoder.stages_2.4.conv2.bias\", \"module.encoder.stages_2.4.conv2.gain\", \"module.encoder.stages_2.4.conv2b.weight\", \"module.encoder.stages_2.4.conv2b.bias\", \"module.encoder.stages_2.4.conv2b.gain\", \"module.encoder.stages_2.4.conv3.weight\", \"module.encoder.stages_2.4.conv3.bias\", \"module.encoder.stages_2.4.conv3.gain\", \"module.encoder.stages_2.4.attn_last.conv.weight\", \"module.encoder.stages_2.5.conv1.weight\", \"module.encoder.stages_2.5.conv1.bias\", \"module.encoder.stages_2.5.conv1.gain\", \"module.encoder.stages_2.5.conv2.weight\", \"module.encoder.stages_2.5.conv2.bias\", \"module.encoder.stages_2.5.conv2.gain\", \"module.encoder.stages_2.5.conv2b.weight\", \"module.encoder.stages_2.5.conv2b.bias\", \"module.encoder.stages_2.5.conv2b.gain\", \"module.encoder.stages_2.5.conv3.weight\", \"module.encoder.stages_2.5.conv3.bias\", \"module.encoder.stages_2.5.conv3.gain\", \"module.encoder.stages_2.5.attn_last.conv.weight\", \"module.encoder.stages_3.0.downsample.conv.weight\", \"module.encoder.stages_3.0.downsample.conv.bias\", \"module.encoder.stages_3.0.downsample.conv.gain\", \"module.encoder.stages_3.0.conv1.weight\", \"module.encoder.stages_3.0.conv1.bias\", \"module.encoder.stages_3.0.conv1.gain\", \"module.encoder.stages_3.0.conv2.weight\", \"module.encoder.stages_3.0.conv2.bias\", \"module.encoder.stages_3.0.conv2.gain\", \"module.encoder.stages_3.0.conv2b.weight\", \"module.encoder.stages_3.0.conv2b.bias\", \"module.encoder.stages_3.0.conv2b.gain\", \"module.encoder.stages_3.0.conv3.weight\", \"module.encoder.stages_3.0.conv3.bias\", \"module.encoder.stages_3.0.conv3.gain\", \"module.encoder.stages_3.0.attn_last.conv.weight\", \"module.encoder.stages_3.1.conv1.weight\", \"module.encoder.stages_3.1.conv1.bias\", \"module.encoder.stages_3.1.conv1.gain\", \"module.encoder.stages_3.1.conv2.weight\", \"module.encoder.stages_3.1.conv2.bias\", \"module.encoder.stages_3.1.conv2.gain\", \"module.encoder.stages_3.1.conv2b.weight\", \"module.encoder.stages_3.1.conv2b.bias\", \"module.encoder.stages_3.1.conv2b.gain\", \"module.encoder.stages_3.1.conv3.weight\", \"module.encoder.stages_3.1.conv3.bias\", \"module.encoder.stages_3.1.conv3.gain\", \"module.encoder.stages_3.1.attn_last.conv.weight\", \"module.encoder.stages_3.2.conv1.weight\", \"module.encoder.stages_3.2.conv1.bias\", \"module.encoder.stages_3.2.conv1.gain\", \"module.encoder.stages_3.2.conv2.weight\", \"module.encoder.stages_3.2.conv2.bias\", \"module.encoder.stages_3.2.conv2.gain\", \"module.encoder.stages_3.2.conv2b.weight\", \"module.encoder.stages_3.2.conv2b.bias\", \"module.encoder.stages_3.2.conv2b.gain\", \"module.encoder.stages_3.2.conv3.weight\", \"module.encoder.stages_3.2.conv3.bias\", \"module.encoder.stages_3.2.conv3.gain\", \"module.encoder.stages_3.2.attn_last.conv.weight\", \"module.encoder.final_conv.weight\", \"module.encoder.final_conv.bias\", \"module.encoder.final_conv.gain\", \"module.gem.p\", \"module.head1.weight\", \"module.head1.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"stem.conv1.weight\", \"stem.conv1.bias\", \"stem.conv1.gain\", \"stem.conv2.weight\", \"stem.conv2.bias\", \"stem.conv2.gain\", \"stem.conv3.weight\", \"stem.conv3.bias\", \"stem.conv3.gain\", \"stem.conv4.weight\", \"stem.conv4.bias\", \"stem.conv4.gain\", \"stages.0.0.downsample.conv.weight\", \"stages.0.0.downsample.conv.bias\", \"stages.0.0.downsample.conv.gain\", \"stages.0.0.conv1.weight\", \"stages.0.0.conv1.bias\", \"stages.0.0.conv1.gain\", \"stages.0.0.conv2.weight\", \"stages.0.0.conv2.bias\", \"stages.0.0.conv2.gain\", \"stages.0.0.conv2b.weight\", \"stages.0.0.conv2b.bias\", \"stages.0.0.conv2b.gain\", \"stages.0.0.conv3.weight\", \"stages.0.0.conv3.bias\", \"stages.0.0.conv3.gain\", \"stages.0.0.attn_last.conv.weight\", \"stages.1.0.downsample.conv.weight\", \"stages.1.0.downsample.conv.bias\", \"stages.1.0.downsample.conv.gain\", \"stages.1.0.conv1.weight\", \"stages.1.0.conv1.bias\", \"stages.1.0.conv1.gain\", \"stages.1.0.conv2.weight\", \"stages.1.0.conv2.bias\", \"stages.1.0.conv2.gain\", \"stages.1.0.conv2b.weight\", \"stages.1.0.conv2b.bias\", \"stages.1.0.conv2b.gain\", \"stages.1.0.conv3.weight\", \"stages.1.0.conv3.bias\", \"stages.1.0.conv3.gain\", \"stages.1.0.attn_last.conv.weight\", \"stages.1.1.conv1.weight\", \"stages.1.1.conv1.bias\", \"stages.1.1.conv1.gain\", \"stages.1.1.conv2.weight\", \"stages.1.1.conv2.bias\", \"stages.1.1.conv2.gain\", \"stages.1.1.conv2b.weight\", \"stages.1.1.conv2b.bias\", \"stages.1.1.conv2b.gain\", \"stages.1.1.conv3.weight\", \"stages.1.1.conv3.bias\", \"stages.1.1.conv3.gain\", \"stages.1.1.attn_last.conv.weight\", \"stages.2.0.downsample.conv.weight\", \"stages.2.0.downsample.conv.bias\", \"stages.2.0.downsample.conv.gain\", \"stages.2.0.conv1.weight\", \"stages.2.0.conv1.bias\", \"stages.2.0.conv1.gain\", \"stages.2.0.conv2.weight\", \"stages.2.0.conv2.bias\", \"stages.2.0.conv2.gain\", \"stages.2.0.conv2b.weight\", \"stages.2.0.conv2b.bias\", \"stages.2.0.conv2b.gain\", \"stages.2.0.conv3.weight\", \"stages.2.0.conv3.bias\", \"stages.2.0.conv3.gain\", \"stages.2.0.attn_last.conv.weight\", \"stages.2.1.conv1.weight\", \"stages.2.1.conv1.bias\", \"stages.2.1.conv1.gain\", \"stages.2.1.conv2.weight\", \"stages.2.1.conv2.bias\", \"stages.2.1.conv2.gain\", \"stages.2.1.conv2b.weight\", \"stages.2.1.conv2b.bias\", \"stages.2.1.conv2b.gain\", \"stages.2.1.conv3.weight\", \"stages.2.1.conv3.bias\", \"stages.2.1.conv3.gain\", \"stages.2.1.attn_last.conv.weight\", \"stages.2.2.conv1.weight\", \"stages.2.2.conv1.bias\", \"stages.2.2.conv1.gain\", \"stages.2.2.conv2.weight\", \"stages.2.2.conv2.bias\", \"stages.2.2.conv2.gain\", \"stages.2.2.conv2b.weight\", \"stages.2.2.conv2b.bias\", \"stages.2.2.conv2b.gain\", \"stages.2.2.conv3.weight\", \"stages.2.2.conv3.bias\", \"stages.2.2.conv3.gain\", \"stages.2.2.attn_last.conv.weight\", \"stages.2.3.conv1.weight\", \"stages.2.3.conv1.bias\", \"stages.2.3.conv1.gain\", \"stages.2.3.conv2.weight\", \"stages.2.3.conv2.bias\", \"stages.2.3.conv2.gain\", \"stages.2.3.conv2b.weight\", \"stages.2.3.conv2b.bias\", \"stages.2.3.conv2b.gain\", \"stages.2.3.conv3.weight\", \"stages.2.3.conv3.bias\", \"stages.2.3.conv3.gain\", \"stages.2.3.attn_last.conv.weight\", \"stages.2.4.conv1.weight\", \"stages.2.4.conv1.bias\", \"stages.2.4.conv1.gain\", \"stages.2.4.conv2.weight\", \"stages.2.4.conv2.bias\", \"stages.2.4.conv2.gain\", \"stages.2.4.conv2b.weight\", \"stages.2.4.conv2b.bias\", \"stages.2.4.conv2b.gain\", \"stages.2.4.conv3.weight\", \"stages.2.4.conv3.bias\", \"stages.2.4.conv3.gain\", \"stages.2.4.attn_last.conv.weight\", \"stages.2.5.conv1.weight\", \"stages.2.5.conv1.bias\", \"stages.2.5.conv1.gain\", \"stages.2.5.conv2.weight\", \"stages.2.5.conv2.bias\", \"stages.2.5.conv2.gain\", \"stages.2.5.conv2b.weight\", \"stages.2.5.conv2b.bias\", \"stages.2.5.conv2b.gain\", \"stages.2.5.conv3.weight\", \"stages.2.5.conv3.bias\", \"stages.2.5.conv3.gain\", \"stages.2.5.attn_last.conv.weight\", \"stages.3.0.downsample.conv.weight\", \"stages.3.0.downsample.conv.bias\", \"stages.3.0.downsample.conv.gain\", \"stages.3.0.conv1.weight\", \"stages.3.0.conv1.bias\", \"stages.3.0.conv1.gain\", \"stages.3.0.conv2.weight\", \"stages.3.0.conv2.bias\", \"stages.3.0.conv2.gain\", \"stages.3.0.conv2b.weight\", \"stages.3.0.conv2b.bias\", \"stages.3.0.conv2b.gain\", \"stages.3.0.conv3.weight\", \"stages.3.0.conv3.bias\", \"stages.3.0.conv3.gain\", \"stages.3.0.attn_last.conv.weight\", \"stages.3.1.conv1.weight\", \"stages.3.1.conv1.bias\", \"stages.3.1.conv1.gain\", \"stages.3.1.conv2.weight\", \"stages.3.1.conv2.bias\", \"stages.3.1.conv2.gain\", \"stages.3.1.conv2b.weight\", \"stages.3.1.conv2b.bias\", \"stages.3.1.conv2b.gain\", \"stages.3.1.conv3.weight\", \"stages.3.1.conv3.bias\", \"stages.3.1.conv3.gain\", \"stages.3.1.attn_last.conv.weight\", \"stages.3.2.conv1.weight\", \"stages.3.2.conv1.bias\", \"stages.3.2.conv1.gain\", \"stages.3.2.conv2.weight\", \"stages.3.2.conv2.bias\", \"stages.3.2.conv2.gain\", \"stages.3.2.conv2b.weight\", \"stages.3.2.conv2b.bias\", \"stages.3.2.conv2b.gain\", \"stages.3.2.conv3.weight\", \"stages.3.2.conv3.bias\", \"stages.3.2.conv3.gain\", \"stages.3.2.attn_last.conv.weight\", \"final_conv.weight\", \"final_conv.bias\", \"final_conv.gain\". \n",
      "\n",
      "\n",
      " => current model:  TimmClassifier_v2\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth'\n",
      "odict_keys(['stem.conv1.weight', 'stem.conv1.bias', 'stem.conv1.gain', 'stem.conv2.weight', 'stem.conv2.bias', 'stem.conv2.gain', 'stem.conv3.weight', 'stem.conv3.bias', 'stem.conv3.gain', 'stem.conv4.weight', 'stem.conv4.bias', 'stem.conv4.gain', 'stages.0.0.downsample.conv.weight', 'stages.0.0.downsample.conv.bias', 'stages.0.0.downsample.conv.gain', 'stages.0.0.conv1.weight', 'stages.0.0.conv1.bias', 'stages.0.0.conv1.gain', 'stages.0.0.conv2.weight', 'stages.0.0.conv2.bias', 'stages.0.0.conv2.gain', 'stages.0.0.conv2b.weight', 'stages.0.0.conv2b.bias', 'stages.0.0.conv2b.gain', 'stages.0.0.conv3.weight', 'stages.0.0.conv3.bias', 'stages.0.0.conv3.gain', 'stages.0.0.attn_last.conv.weight', 'stages.1.0.downsample.conv.weight', 'stages.1.0.downsample.conv.bias', 'stages.1.0.downsample.conv.gain', 'stages.1.0.conv1.weight', 'stages.1.0.conv1.bias', 'stages.1.0.conv1.gain', 'stages.1.0.conv2.weight', 'stages.1.0.conv2.bias', 'stages.1.0.conv2.gain', 'stages.1.0.conv2b.weight', 'stages.1.0.conv2b.bias', 'stages.1.0.conv2b.gain', 'stages.1.0.conv3.weight', 'stages.1.0.conv3.bias', 'stages.1.0.conv3.gain', 'stages.1.0.attn_last.conv.weight', 'stages.1.1.conv1.weight', 'stages.1.1.conv1.bias', 'stages.1.1.conv1.gain', 'stages.1.1.conv2.weight', 'stages.1.1.conv2.bias', 'stages.1.1.conv2.gain', 'stages.1.1.conv2b.weight', 'stages.1.1.conv2b.bias', 'stages.1.1.conv2b.gain', 'stages.1.1.conv3.weight', 'stages.1.1.conv3.bias', 'stages.1.1.conv3.gain', 'stages.1.1.attn_last.conv.weight', 'stages.2.0.downsample.conv.weight', 'stages.2.0.downsample.conv.bias', 'stages.2.0.downsample.conv.gain', 'stages.2.0.conv1.weight', 'stages.2.0.conv1.bias', 'stages.2.0.conv1.gain', 'stages.2.0.conv2.weight', 'stages.2.0.conv2.bias', 'stages.2.0.conv2.gain', 'stages.2.0.conv2b.weight', 'stages.2.0.conv2b.bias', 'stages.2.0.conv2b.gain', 'stages.2.0.conv3.weight', 'stages.2.0.conv3.bias', 'stages.2.0.conv3.gain', 'stages.2.0.attn_last.conv.weight', 'stages.2.1.conv1.weight', 'stages.2.1.conv1.bias', 'stages.2.1.conv1.gain', 'stages.2.1.conv2.weight', 'stages.2.1.conv2.bias', 'stages.2.1.conv2.gain', 'stages.2.1.conv2b.weight', 'stages.2.1.conv2b.bias', 'stages.2.1.conv2b.gain', 'stages.2.1.conv3.weight', 'stages.2.1.conv3.bias', 'stages.2.1.conv3.gain', 'stages.2.1.attn_last.conv.weight', 'stages.2.2.conv1.weight', 'stages.2.2.conv1.bias', 'stages.2.2.conv1.gain', 'stages.2.2.conv2.weight', 'stages.2.2.conv2.bias', 'stages.2.2.conv2.gain', 'stages.2.2.conv2b.weight', 'stages.2.2.conv2b.bias', 'stages.2.2.conv2b.gain', 'stages.2.2.conv3.weight', 'stages.2.2.conv3.bias', 'stages.2.2.conv3.gain', 'stages.2.2.attn_last.conv.weight', 'stages.2.3.conv1.weight', 'stages.2.3.conv1.bias', 'stages.2.3.conv1.gain', 'stages.2.3.conv2.weight', 'stages.2.3.conv2.bias', 'stages.2.3.conv2.gain', 'stages.2.3.conv2b.weight', 'stages.2.3.conv2b.bias', 'stages.2.3.conv2b.gain', 'stages.2.3.conv3.weight', 'stages.2.3.conv3.bias', 'stages.2.3.conv3.gain', 'stages.2.3.attn_last.conv.weight', 'stages.2.4.conv1.weight', 'stages.2.4.conv1.bias', 'stages.2.4.conv1.gain', 'stages.2.4.conv2.weight', 'stages.2.4.conv2.bias', 'stages.2.4.conv2.gain', 'stages.2.4.conv2b.weight', 'stages.2.4.conv2b.bias', 'stages.2.4.conv2b.gain', 'stages.2.4.conv3.weight', 'stages.2.4.conv3.bias', 'stages.2.4.conv3.gain', 'stages.2.4.attn_last.conv.weight', 'stages.2.5.conv1.weight', 'stages.2.5.conv1.bias', 'stages.2.5.conv1.gain', 'stages.2.5.conv2.weight', 'stages.2.5.conv2.bias', 'stages.2.5.conv2.gain', 'stages.2.5.conv2b.weight', 'stages.2.5.conv2b.bias', 'stages.2.5.conv2b.gain', 'stages.2.5.conv3.weight', 'stages.2.5.conv3.bias', 'stages.2.5.conv3.gain', 'stages.2.5.attn_last.conv.weight', 'stages.3.0.downsample.conv.weight', 'stages.3.0.downsample.conv.bias', 'stages.3.0.downsample.conv.gain', 'stages.3.0.conv1.weight', 'stages.3.0.conv1.bias', 'stages.3.0.conv1.gain', 'stages.3.0.conv2.weight', 'stages.3.0.conv2.bias', 'stages.3.0.conv2.gain', 'stages.3.0.conv2b.weight', 'stages.3.0.conv2b.bias', 'stages.3.0.conv2b.gain', 'stages.3.0.conv3.weight', 'stages.3.0.conv3.bias', 'stages.3.0.conv3.gain', 'stages.3.0.attn_last.conv.weight', 'stages.3.1.conv1.weight', 'stages.3.1.conv1.bias', 'stages.3.1.conv1.gain', 'stages.3.1.conv2.weight', 'stages.3.1.conv2.bias', 'stages.3.1.conv2.gain', 'stages.3.1.conv2b.weight', 'stages.3.1.conv2b.bias', 'stages.3.1.conv2b.gain', 'stages.3.1.conv3.weight', 'stages.3.1.conv3.bias', 'stages.3.1.conv3.gain', 'stages.3.1.attn_last.conv.weight', 'stages.3.2.conv1.weight', 'stages.3.2.conv1.bias', 'stages.3.2.conv1.gain', 'stages.3.2.conv2.weight', 'stages.3.2.conv2.bias', 'stages.3.2.conv2.gain', 'stages.3.2.conv2b.weight', 'stages.3.2.conv2b.bias', 'stages.3.2.conv2b.gain', 'stages.3.2.conv3.weight', 'stages.3.2.conv3.bias', 'stages.3.2.conv3.gain', 'stages.3.2.attn_last.conv.weight', 'final_conv.weight', 'final_conv.bias', 'final_conv.gain'])\n",
      "model not found Error(s) in loading state_dict for DataParallel:\n",
      "\tMissing key(s) in state_dict: \"module.mel_spec.spectrogram.window\", \"module.mel_spec.mel_scale.fb\", \"module.wav2img.0.spectrogram.window\", \"module.wav2img.0.mel_scale.fb\", \"module.encoder.stem_conv1.weight\", \"module.encoder.stem_conv1.bias\", \"module.encoder.stem_conv1.gain\", \"module.encoder.stem_conv2.weight\", \"module.encoder.stem_conv2.bias\", \"module.encoder.stem_conv2.gain\", \"module.encoder.stem_conv3.weight\", \"module.encoder.stem_conv3.bias\", \"module.encoder.stem_conv3.gain\", \"module.encoder.stem_conv4.weight\", \"module.encoder.stem_conv4.bias\", \"module.encoder.stem_conv4.gain\", \"module.encoder.stages_0.0.downsample.conv.weight\", \"module.encoder.stages_0.0.downsample.conv.bias\", \"module.encoder.stages_0.0.downsample.conv.gain\", \"module.encoder.stages_0.0.conv1.weight\", \"module.encoder.stages_0.0.conv1.bias\", \"module.encoder.stages_0.0.conv1.gain\", \"module.encoder.stages_0.0.conv2.weight\", \"module.encoder.stages_0.0.conv2.bias\", \"module.encoder.stages_0.0.conv2.gain\", \"module.encoder.stages_0.0.conv2b.weight\", \"module.encoder.stages_0.0.conv2b.bias\", \"module.encoder.stages_0.0.conv2b.gain\", \"module.encoder.stages_0.0.conv3.weight\", \"module.encoder.stages_0.0.conv3.bias\", \"module.encoder.stages_0.0.conv3.gain\", \"module.encoder.stages_0.0.attn_last.conv.weight\", \"module.encoder.stages_1.0.downsample.conv.weight\", \"module.encoder.stages_1.0.downsample.conv.bias\", \"module.encoder.stages_1.0.downsample.conv.gain\", \"module.encoder.stages_1.0.conv1.weight\", \"module.encoder.stages_1.0.conv1.bias\", \"module.encoder.stages_1.0.conv1.gain\", \"module.encoder.stages_1.0.conv2.weight\", \"module.encoder.stages_1.0.conv2.bias\", \"module.encoder.stages_1.0.conv2.gain\", \"module.encoder.stages_1.0.conv2b.weight\", \"module.encoder.stages_1.0.conv2b.bias\", \"module.encoder.stages_1.0.conv2b.gain\", \"module.encoder.stages_1.0.conv3.weight\", \"module.encoder.stages_1.0.conv3.bias\", \"module.encoder.stages_1.0.conv3.gain\", \"module.encoder.stages_1.0.attn_last.conv.weight\", \"module.encoder.stages_1.1.conv1.weight\", \"module.encoder.stages_1.1.conv1.bias\", \"module.encoder.stages_1.1.conv1.gain\", \"module.encoder.stages_1.1.conv2.weight\", \"module.encoder.stages_1.1.conv2.bias\", \"module.encoder.stages_1.1.conv2.gain\", \"module.encoder.stages_1.1.conv2b.weight\", \"module.encoder.stages_1.1.conv2b.bias\", \"module.encoder.stages_1.1.conv2b.gain\", \"module.encoder.stages_1.1.conv3.weight\", \"module.encoder.stages_1.1.conv3.bias\", \"module.encoder.stages_1.1.conv3.gain\", \"module.encoder.stages_1.1.attn_last.conv.weight\", \"module.encoder.stages_2.0.downsample.conv.weight\", \"module.encoder.stages_2.0.downsample.conv.bias\", \"module.encoder.stages_2.0.downsample.conv.gain\", \"module.encoder.stages_2.0.conv1.weight\", \"module.encoder.stages_2.0.conv1.bias\", \"module.encoder.stages_2.0.conv1.gain\", \"module.encoder.stages_2.0.conv2.weight\", \"module.encoder.stages_2.0.conv2.bias\", \"module.encoder.stages_2.0.conv2.gain\", \"module.encoder.stages_2.0.conv2b.weight\", \"module.encoder.stages_2.0.conv2b.bias\", \"module.encoder.stages_2.0.conv2b.gain\", \"module.encoder.stages_2.0.conv3.weight\", \"module.encoder.stages_2.0.conv3.bias\", \"module.encoder.stages_2.0.conv3.gain\", \"module.encoder.stages_2.0.attn_last.conv.weight\", \"module.encoder.stages_2.1.conv1.weight\", \"module.encoder.stages_2.1.conv1.bias\", \"module.encoder.stages_2.1.conv1.gain\", \"module.encoder.stages_2.1.conv2.weight\", \"module.encoder.stages_2.1.conv2.bias\", \"module.encoder.stages_2.1.conv2.gain\", \"module.encoder.stages_2.1.conv2b.weight\", \"module.encoder.stages_2.1.conv2b.bias\", \"module.encoder.stages_2.1.conv2b.gain\", \"module.encoder.stages_2.1.conv3.weight\", \"module.encoder.stages_2.1.conv3.bias\", \"module.encoder.stages_2.1.conv3.gain\", \"module.encoder.stages_2.1.attn_last.conv.weight\", \"module.encoder.stages_2.2.conv1.weight\", \"module.encoder.stages_2.2.conv1.bias\", \"module.encoder.stages_2.2.conv1.gain\", \"module.encoder.stages_2.2.conv2.weight\", \"module.encoder.stages_2.2.conv2.bias\", \"module.encoder.stages_2.2.conv2.gain\", \"module.encoder.stages_2.2.conv2b.weight\", \"module.encoder.stages_2.2.conv2b.bias\", \"module.encoder.stages_2.2.conv2b.gain\", \"module.encoder.stages_2.2.conv3.weight\", \"module.encoder.stages_2.2.conv3.bias\", \"module.encoder.stages_2.2.conv3.gain\", \"module.encoder.stages_2.2.attn_last.conv.weight\", \"module.encoder.stages_2.3.conv1.weight\", \"module.encoder.stages_2.3.conv1.bias\", \"module.encoder.stages_2.3.conv1.gain\", \"module.encoder.stages_2.3.conv2.weight\", \"module.encoder.stages_2.3.conv2.bias\", \"module.encoder.stages_2.3.conv2.gain\", \"module.encoder.stages_2.3.conv2b.weight\", \"module.encoder.stages_2.3.conv2b.bias\", \"module.encoder.stages_2.3.conv2b.gain\", \"module.encoder.stages_2.3.conv3.weight\", \"module.encoder.stages_2.3.conv3.bias\", \"module.encoder.stages_2.3.conv3.gain\", \"module.encoder.stages_2.3.attn_last.conv.weight\", \"module.encoder.stages_2.4.conv1.weight\", \"module.encoder.stages_2.4.conv1.bias\", \"module.encoder.stages_2.4.conv1.gain\", \"module.encoder.stages_2.4.conv2.weight\", \"module.encoder.stages_2.4.conv2.bias\", \"module.encoder.stages_2.4.conv2.gain\", \"module.encoder.stages_2.4.conv2b.weight\", \"module.encoder.stages_2.4.conv2b.bias\", \"module.encoder.stages_2.4.conv2b.gain\", \"module.encoder.stages_2.4.conv3.weight\", \"module.encoder.stages_2.4.conv3.bias\", \"module.encoder.stages_2.4.conv3.gain\", \"module.encoder.stages_2.4.attn_last.conv.weight\", \"module.encoder.stages_2.5.conv1.weight\", \"module.encoder.stages_2.5.conv1.bias\", \"module.encoder.stages_2.5.conv1.gain\", \"module.encoder.stages_2.5.conv2.weight\", \"module.encoder.stages_2.5.conv2.bias\", \"module.encoder.stages_2.5.conv2.gain\", \"module.encoder.stages_2.5.conv2b.weight\", \"module.encoder.stages_2.5.conv2b.bias\", \"module.encoder.stages_2.5.conv2b.gain\", \"module.encoder.stages_2.5.conv3.weight\", \"module.encoder.stages_2.5.conv3.bias\", \"module.encoder.stages_2.5.conv3.gain\", \"module.encoder.stages_2.5.attn_last.conv.weight\", \"module.encoder.stages_3.0.downsample.conv.weight\", \"module.encoder.stages_3.0.downsample.conv.bias\", \"module.encoder.stages_3.0.downsample.conv.gain\", \"module.encoder.stages_3.0.conv1.weight\", \"module.encoder.stages_3.0.conv1.bias\", \"module.encoder.stages_3.0.conv1.gain\", \"module.encoder.stages_3.0.conv2.weight\", \"module.encoder.stages_3.0.conv2.bias\", \"module.encoder.stages_3.0.conv2.gain\", \"module.encoder.stages_3.0.conv2b.weight\", \"module.encoder.stages_3.0.conv2b.bias\", \"module.encoder.stages_3.0.conv2b.gain\", \"module.encoder.stages_3.0.conv3.weight\", \"module.encoder.stages_3.0.conv3.bias\", \"module.encoder.stages_3.0.conv3.gain\", \"module.encoder.stages_3.0.attn_last.conv.weight\", \"module.encoder.stages_3.1.conv1.weight\", \"module.encoder.stages_3.1.conv1.bias\", \"module.encoder.stages_3.1.conv1.gain\", \"module.encoder.stages_3.1.conv2.weight\", \"module.encoder.stages_3.1.conv2.bias\", \"module.encoder.stages_3.1.conv2.gain\", \"module.encoder.stages_3.1.conv2b.weight\", \"module.encoder.stages_3.1.conv2b.bias\", \"module.encoder.stages_3.1.conv2b.gain\", \"module.encoder.stages_3.1.conv3.weight\", \"module.encoder.stages_3.1.conv3.bias\", \"module.encoder.stages_3.1.conv3.gain\", \"module.encoder.stages_3.1.attn_last.conv.weight\", \"module.encoder.stages_3.2.conv1.weight\", \"module.encoder.stages_3.2.conv1.bias\", \"module.encoder.stages_3.2.conv1.gain\", \"module.encoder.stages_3.2.conv2.weight\", \"module.encoder.stages_3.2.conv2.bias\", \"module.encoder.stages_3.2.conv2.gain\", \"module.encoder.stages_3.2.conv2b.weight\", \"module.encoder.stages_3.2.conv2b.bias\", \"module.encoder.stages_3.2.conv2b.gain\", \"module.encoder.stages_3.2.conv3.weight\", \"module.encoder.stages_3.2.conv3.bias\", \"module.encoder.stages_3.2.conv3.gain\", \"module.encoder.stages_3.2.attn_last.conv.weight\", \"module.encoder.final_conv.weight\", \"module.encoder.final_conv.bias\", \"module.encoder.final_conv.gain\", \"module.gem.p\", \"module.head1.weight\", \"module.head1.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"stem.conv1.weight\", \"stem.conv1.bias\", \"stem.conv1.gain\", \"stem.conv2.weight\", \"stem.conv2.bias\", \"stem.conv2.gain\", \"stem.conv3.weight\", \"stem.conv3.bias\", \"stem.conv3.gain\", \"stem.conv4.weight\", \"stem.conv4.bias\", \"stem.conv4.gain\", \"stages.0.0.downsample.conv.weight\", \"stages.0.0.downsample.conv.bias\", \"stages.0.0.downsample.conv.gain\", \"stages.0.0.conv1.weight\", \"stages.0.0.conv1.bias\", \"stages.0.0.conv1.gain\", \"stages.0.0.conv2.weight\", \"stages.0.0.conv2.bias\", \"stages.0.0.conv2.gain\", \"stages.0.0.conv2b.weight\", \"stages.0.0.conv2b.bias\", \"stages.0.0.conv2b.gain\", \"stages.0.0.conv3.weight\", \"stages.0.0.conv3.bias\", \"stages.0.0.conv3.gain\", \"stages.0.0.attn_last.conv.weight\", \"stages.1.0.downsample.conv.weight\", \"stages.1.0.downsample.conv.bias\", \"stages.1.0.downsample.conv.gain\", \"stages.1.0.conv1.weight\", \"stages.1.0.conv1.bias\", \"stages.1.0.conv1.gain\", \"stages.1.0.conv2.weight\", \"stages.1.0.conv2.bias\", \"stages.1.0.conv2.gain\", \"stages.1.0.conv2b.weight\", \"stages.1.0.conv2b.bias\", \"stages.1.0.conv2b.gain\", \"stages.1.0.conv3.weight\", \"stages.1.0.conv3.bias\", \"stages.1.0.conv3.gain\", \"stages.1.0.attn_last.conv.weight\", \"stages.1.1.conv1.weight\", \"stages.1.1.conv1.bias\", \"stages.1.1.conv1.gain\", \"stages.1.1.conv2.weight\", \"stages.1.1.conv2.bias\", \"stages.1.1.conv2.gain\", \"stages.1.1.conv2b.weight\", \"stages.1.1.conv2b.bias\", \"stages.1.1.conv2b.gain\", \"stages.1.1.conv3.weight\", \"stages.1.1.conv3.bias\", \"stages.1.1.conv3.gain\", \"stages.1.1.attn_last.conv.weight\", \"stages.2.0.downsample.conv.weight\", \"stages.2.0.downsample.conv.bias\", \"stages.2.0.downsample.conv.gain\", \"stages.2.0.conv1.weight\", \"stages.2.0.conv1.bias\", \"stages.2.0.conv1.gain\", \"stages.2.0.conv2.weight\", \"stages.2.0.conv2.bias\", \"stages.2.0.conv2.gain\", \"stages.2.0.conv2b.weight\", \"stages.2.0.conv2b.bias\", \"stages.2.0.conv2b.gain\", \"stages.2.0.conv3.weight\", \"stages.2.0.conv3.bias\", \"stages.2.0.conv3.gain\", \"stages.2.0.attn_last.conv.weight\", \"stages.2.1.conv1.weight\", \"stages.2.1.conv1.bias\", \"stages.2.1.conv1.gain\", \"stages.2.1.conv2.weight\", \"stages.2.1.conv2.bias\", \"stages.2.1.conv2.gain\", \"stages.2.1.conv2b.weight\", \"stages.2.1.conv2b.bias\", \"stages.2.1.conv2b.gain\", \"stages.2.1.conv3.weight\", \"stages.2.1.conv3.bias\", \"stages.2.1.conv3.gain\", \"stages.2.1.attn_last.conv.weight\", \"stages.2.2.conv1.weight\", \"stages.2.2.conv1.bias\", \"stages.2.2.conv1.gain\", \"stages.2.2.conv2.weight\", \"stages.2.2.conv2.bias\", \"stages.2.2.conv2.gain\", \"stages.2.2.conv2b.weight\", \"stages.2.2.conv2b.bias\", \"stages.2.2.conv2b.gain\", \"stages.2.2.conv3.weight\", \"stages.2.2.conv3.bias\", \"stages.2.2.conv3.gain\", \"stages.2.2.attn_last.conv.weight\", \"stages.2.3.conv1.weight\", \"stages.2.3.conv1.bias\", \"stages.2.3.conv1.gain\", \"stages.2.3.conv2.weight\", \"stages.2.3.conv2.bias\", \"stages.2.3.conv2.gain\", \"stages.2.3.conv2b.weight\", \"stages.2.3.conv2b.bias\", \"stages.2.3.conv2b.gain\", \"stages.2.3.conv3.weight\", \"stages.2.3.conv3.bias\", \"stages.2.3.conv3.gain\", \"stages.2.3.attn_last.conv.weight\", \"stages.2.4.conv1.weight\", \"stages.2.4.conv1.bias\", \"stages.2.4.conv1.gain\", \"stages.2.4.conv2.weight\", \"stages.2.4.conv2.bias\", \"stages.2.4.conv2.gain\", \"stages.2.4.conv2b.weight\", \"stages.2.4.conv2b.bias\", \"stages.2.4.conv2b.gain\", \"stages.2.4.conv3.weight\", \"stages.2.4.conv3.bias\", \"stages.2.4.conv3.gain\", \"stages.2.4.attn_last.conv.weight\", \"stages.2.5.conv1.weight\", \"stages.2.5.conv1.bias\", \"stages.2.5.conv1.gain\", \"stages.2.5.conv2.weight\", \"stages.2.5.conv2.bias\", \"stages.2.5.conv2.gain\", \"stages.2.5.conv2b.weight\", \"stages.2.5.conv2b.bias\", \"stages.2.5.conv2b.gain\", \"stages.2.5.conv3.weight\", \"stages.2.5.conv3.bias\", \"stages.2.5.conv3.gain\", \"stages.2.5.attn_last.conv.weight\", \"stages.3.0.downsample.conv.weight\", \"stages.3.0.downsample.conv.bias\", \"stages.3.0.downsample.conv.gain\", \"stages.3.0.conv1.weight\", \"stages.3.0.conv1.bias\", \"stages.3.0.conv1.gain\", \"stages.3.0.conv2.weight\", \"stages.3.0.conv2.bias\", \"stages.3.0.conv2.gain\", \"stages.3.0.conv2b.weight\", \"stages.3.0.conv2b.bias\", \"stages.3.0.conv2b.gain\", \"stages.3.0.conv3.weight\", \"stages.3.0.conv3.bias\", \"stages.3.0.conv3.gain\", \"stages.3.0.attn_last.conv.weight\", \"stages.3.1.conv1.weight\", \"stages.3.1.conv1.bias\", \"stages.3.1.conv1.gain\", \"stages.3.1.conv2.weight\", \"stages.3.1.conv2.bias\", \"stages.3.1.conv2.gain\", \"stages.3.1.conv2b.weight\", \"stages.3.1.conv2b.bias\", \"stages.3.1.conv2b.gain\", \"stages.3.1.conv3.weight\", \"stages.3.1.conv3.bias\", \"stages.3.1.conv3.gain\", \"stages.3.1.attn_last.conv.weight\", \"stages.3.2.conv1.weight\", \"stages.3.2.conv1.bias\", \"stages.3.2.conv1.gain\", \"stages.3.2.conv2.weight\", \"stages.3.2.conv2.bias\", \"stages.3.2.conv2.gain\", \"stages.3.2.conv2b.weight\", \"stages.3.2.conv2b.bias\", \"stages.3.2.conv2b.gain\", \"stages.3.2.conv3.weight\", \"stages.3.2.conv3.bias\", \"stages.3.2.conv3.gain\", \"stages.3.2.attn_last.conv.weight\", \"final_conv.weight\", \"final_conv.bias\", \"final_conv.gain\". \n",
      "\n",
      "\n",
      " => current model:  TimmClassifier2021\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth'\n",
      "odict_keys(['stem.conv1.weight', 'stem.conv1.bias', 'stem.conv1.gain', 'stem.conv2.weight', 'stem.conv2.bias', 'stem.conv2.gain', 'stem.conv3.weight', 'stem.conv3.bias', 'stem.conv3.gain', 'stem.conv4.weight', 'stem.conv4.bias', 'stem.conv4.gain', 'stages.0.0.downsample.conv.weight', 'stages.0.0.downsample.conv.bias', 'stages.0.0.downsample.conv.gain', 'stages.0.0.conv1.weight', 'stages.0.0.conv1.bias', 'stages.0.0.conv1.gain', 'stages.0.0.conv2.weight', 'stages.0.0.conv2.bias', 'stages.0.0.conv2.gain', 'stages.0.0.conv2b.weight', 'stages.0.0.conv2b.bias', 'stages.0.0.conv2b.gain', 'stages.0.0.conv3.weight', 'stages.0.0.conv3.bias', 'stages.0.0.conv3.gain', 'stages.0.0.attn_last.conv.weight', 'stages.1.0.downsample.conv.weight', 'stages.1.0.downsample.conv.bias', 'stages.1.0.downsample.conv.gain', 'stages.1.0.conv1.weight', 'stages.1.0.conv1.bias', 'stages.1.0.conv1.gain', 'stages.1.0.conv2.weight', 'stages.1.0.conv2.bias', 'stages.1.0.conv2.gain', 'stages.1.0.conv2b.weight', 'stages.1.0.conv2b.bias', 'stages.1.0.conv2b.gain', 'stages.1.0.conv3.weight', 'stages.1.0.conv3.bias', 'stages.1.0.conv3.gain', 'stages.1.0.attn_last.conv.weight', 'stages.1.1.conv1.weight', 'stages.1.1.conv1.bias', 'stages.1.1.conv1.gain', 'stages.1.1.conv2.weight', 'stages.1.1.conv2.bias', 'stages.1.1.conv2.gain', 'stages.1.1.conv2b.weight', 'stages.1.1.conv2b.bias', 'stages.1.1.conv2b.gain', 'stages.1.1.conv3.weight', 'stages.1.1.conv3.bias', 'stages.1.1.conv3.gain', 'stages.1.1.attn_last.conv.weight', 'stages.2.0.downsample.conv.weight', 'stages.2.0.downsample.conv.bias', 'stages.2.0.downsample.conv.gain', 'stages.2.0.conv1.weight', 'stages.2.0.conv1.bias', 'stages.2.0.conv1.gain', 'stages.2.0.conv2.weight', 'stages.2.0.conv2.bias', 'stages.2.0.conv2.gain', 'stages.2.0.conv2b.weight', 'stages.2.0.conv2b.bias', 'stages.2.0.conv2b.gain', 'stages.2.0.conv3.weight', 'stages.2.0.conv3.bias', 'stages.2.0.conv3.gain', 'stages.2.0.attn_last.conv.weight', 'stages.2.1.conv1.weight', 'stages.2.1.conv1.bias', 'stages.2.1.conv1.gain', 'stages.2.1.conv2.weight', 'stages.2.1.conv2.bias', 'stages.2.1.conv2.gain', 'stages.2.1.conv2b.weight', 'stages.2.1.conv2b.bias', 'stages.2.1.conv2b.gain', 'stages.2.1.conv3.weight', 'stages.2.1.conv3.bias', 'stages.2.1.conv3.gain', 'stages.2.1.attn_last.conv.weight', 'stages.2.2.conv1.weight', 'stages.2.2.conv1.bias', 'stages.2.2.conv1.gain', 'stages.2.2.conv2.weight', 'stages.2.2.conv2.bias', 'stages.2.2.conv2.gain', 'stages.2.2.conv2b.weight', 'stages.2.2.conv2b.bias', 'stages.2.2.conv2b.gain', 'stages.2.2.conv3.weight', 'stages.2.2.conv3.bias', 'stages.2.2.conv3.gain', 'stages.2.2.attn_last.conv.weight', 'stages.2.3.conv1.weight', 'stages.2.3.conv1.bias', 'stages.2.3.conv1.gain', 'stages.2.3.conv2.weight', 'stages.2.3.conv2.bias', 'stages.2.3.conv2.gain', 'stages.2.3.conv2b.weight', 'stages.2.3.conv2b.bias', 'stages.2.3.conv2b.gain', 'stages.2.3.conv3.weight', 'stages.2.3.conv3.bias', 'stages.2.3.conv3.gain', 'stages.2.3.attn_last.conv.weight', 'stages.2.4.conv1.weight', 'stages.2.4.conv1.bias', 'stages.2.4.conv1.gain', 'stages.2.4.conv2.weight', 'stages.2.4.conv2.bias', 'stages.2.4.conv2.gain', 'stages.2.4.conv2b.weight', 'stages.2.4.conv2b.bias', 'stages.2.4.conv2b.gain', 'stages.2.4.conv3.weight', 'stages.2.4.conv3.bias', 'stages.2.4.conv3.gain', 'stages.2.4.attn_last.conv.weight', 'stages.2.5.conv1.weight', 'stages.2.5.conv1.bias', 'stages.2.5.conv1.gain', 'stages.2.5.conv2.weight', 'stages.2.5.conv2.bias', 'stages.2.5.conv2.gain', 'stages.2.5.conv2b.weight', 'stages.2.5.conv2b.bias', 'stages.2.5.conv2b.gain', 'stages.2.5.conv3.weight', 'stages.2.5.conv3.bias', 'stages.2.5.conv3.gain', 'stages.2.5.attn_last.conv.weight', 'stages.3.0.downsample.conv.weight', 'stages.3.0.downsample.conv.bias', 'stages.3.0.downsample.conv.gain', 'stages.3.0.conv1.weight', 'stages.3.0.conv1.bias', 'stages.3.0.conv1.gain', 'stages.3.0.conv2.weight', 'stages.3.0.conv2.bias', 'stages.3.0.conv2.gain', 'stages.3.0.conv2b.weight', 'stages.3.0.conv2b.bias', 'stages.3.0.conv2b.gain', 'stages.3.0.conv3.weight', 'stages.3.0.conv3.bias', 'stages.3.0.conv3.gain', 'stages.3.0.attn_last.conv.weight', 'stages.3.1.conv1.weight', 'stages.3.1.conv1.bias', 'stages.3.1.conv1.gain', 'stages.3.1.conv2.weight', 'stages.3.1.conv2.bias', 'stages.3.1.conv2.gain', 'stages.3.1.conv2b.weight', 'stages.3.1.conv2b.bias', 'stages.3.1.conv2b.gain', 'stages.3.1.conv3.weight', 'stages.3.1.conv3.bias', 'stages.3.1.conv3.gain', 'stages.3.1.attn_last.conv.weight', 'stages.3.2.conv1.weight', 'stages.3.2.conv1.bias', 'stages.3.2.conv1.gain', 'stages.3.2.conv2.weight', 'stages.3.2.conv2.bias', 'stages.3.2.conv2.gain', 'stages.3.2.conv2b.weight', 'stages.3.2.conv2b.bias', 'stages.3.2.conv2b.gain', 'stages.3.2.conv3.weight', 'stages.3.2.conv3.bias', 'stages.3.2.conv3.gain', 'stages.3.2.attn_last.conv.weight', 'final_conv.weight', 'final_conv.bias', 'final_conv.gain'])\n",
      "model not found Error(s) in loading state_dict for DataParallel:\n",
      "\tMissing key(s) in state_dict: \"module.mel_spec.spectrogram.window\", \"module.mel_spec.mel_scale.fb\", \"module.wav2img.0.spectrogram.window\", \"module.wav2img.0.mel_scale.fb\", \"module.backbone.stem.conv1.weight\", \"module.backbone.stem.conv1.bias\", \"module.backbone.stem.conv1.gain\", \"module.backbone.stem.conv2.weight\", \"module.backbone.stem.conv2.bias\", \"module.backbone.stem.conv2.gain\", \"module.backbone.stem.conv3.weight\", \"module.backbone.stem.conv3.bias\", \"module.backbone.stem.conv3.gain\", \"module.backbone.stem.conv4.weight\", \"module.backbone.stem.conv4.bias\", \"module.backbone.stem.conv4.gain\", \"module.backbone.stages.0.0.downsample.conv.weight\", \"module.backbone.stages.0.0.downsample.conv.bias\", \"module.backbone.stages.0.0.downsample.conv.gain\", \"module.backbone.stages.0.0.conv1.weight\", \"module.backbone.stages.0.0.conv1.bias\", \"module.backbone.stages.0.0.conv1.gain\", \"module.backbone.stages.0.0.conv2.weight\", \"module.backbone.stages.0.0.conv2.bias\", \"module.backbone.stages.0.0.conv2.gain\", \"module.backbone.stages.0.0.conv2b.weight\", \"module.backbone.stages.0.0.conv2b.bias\", \"module.backbone.stages.0.0.conv2b.gain\", \"module.backbone.stages.0.0.conv3.weight\", \"module.backbone.stages.0.0.conv3.bias\", \"module.backbone.stages.0.0.conv3.gain\", \"module.backbone.stages.0.0.attn_last.conv.weight\", \"module.backbone.stages.1.0.downsample.conv.weight\", \"module.backbone.stages.1.0.downsample.conv.bias\", \"module.backbone.stages.1.0.downsample.conv.gain\", \"module.backbone.stages.1.0.conv1.weight\", \"module.backbone.stages.1.0.conv1.bias\", \"module.backbone.stages.1.0.conv1.gain\", \"module.backbone.stages.1.0.conv2.weight\", \"module.backbone.stages.1.0.conv2.bias\", \"module.backbone.stages.1.0.conv2.gain\", \"module.backbone.stages.1.0.conv2b.weight\", \"module.backbone.stages.1.0.conv2b.bias\", \"module.backbone.stages.1.0.conv2b.gain\", \"module.backbone.stages.1.0.conv3.weight\", \"module.backbone.stages.1.0.conv3.bias\", \"module.backbone.stages.1.0.conv3.gain\", \"module.backbone.stages.1.0.attn_last.conv.weight\", \"module.backbone.stages.1.1.conv1.weight\", \"module.backbone.stages.1.1.conv1.bias\", \"module.backbone.stages.1.1.conv1.gain\", \"module.backbone.stages.1.1.conv2.weight\", \"module.backbone.stages.1.1.conv2.bias\", \"module.backbone.stages.1.1.conv2.gain\", \"module.backbone.stages.1.1.conv2b.weight\", \"module.backbone.stages.1.1.conv2b.bias\", \"module.backbone.stages.1.1.conv2b.gain\", \"module.backbone.stages.1.1.conv3.weight\", \"module.backbone.stages.1.1.conv3.bias\", \"module.backbone.stages.1.1.conv3.gain\", \"module.backbone.stages.1.1.attn_last.conv.weight\", \"module.backbone.stages.2.0.downsample.conv.weight\", \"module.backbone.stages.2.0.downsample.conv.bias\", \"module.backbone.stages.2.0.downsample.conv.gain\", \"module.backbone.stages.2.0.conv1.weight\", \"module.backbone.stages.2.0.conv1.bias\", \"module.backbone.stages.2.0.conv1.gain\", \"module.backbone.stages.2.0.conv2.weight\", \"module.backbone.stages.2.0.conv2.bias\", \"module.backbone.stages.2.0.conv2.gain\", \"module.backbone.stages.2.0.conv2b.weight\", \"module.backbone.stages.2.0.conv2b.bias\", \"module.backbone.stages.2.0.conv2b.gain\", \"module.backbone.stages.2.0.conv3.weight\", \"module.backbone.stages.2.0.conv3.bias\", \"module.backbone.stages.2.0.conv3.gain\", \"module.backbone.stages.2.0.attn_last.conv.weight\", \"module.backbone.stages.2.1.conv1.weight\", \"module.backbone.stages.2.1.conv1.bias\", \"module.backbone.stages.2.1.conv1.gain\", \"module.backbone.stages.2.1.conv2.weight\", \"module.backbone.stages.2.1.conv2.bias\", \"module.backbone.stages.2.1.conv2.gain\", \"module.backbone.stages.2.1.conv2b.weight\", \"module.backbone.stages.2.1.conv2b.bias\", \"module.backbone.stages.2.1.conv2b.gain\", \"module.backbone.stages.2.1.conv3.weight\", \"module.backbone.stages.2.1.conv3.bias\", \"module.backbone.stages.2.1.conv3.gain\", \"module.backbone.stages.2.1.attn_last.conv.weight\", \"module.backbone.stages.2.2.conv1.weight\", \"module.backbone.stages.2.2.conv1.bias\", \"module.backbone.stages.2.2.conv1.gain\", \"module.backbone.stages.2.2.conv2.weight\", \"module.backbone.stages.2.2.conv2.bias\", \"module.backbone.stages.2.2.conv2.gain\", \"module.backbone.stages.2.2.conv2b.weight\", \"module.backbone.stages.2.2.conv2b.bias\", \"module.backbone.stages.2.2.conv2b.gain\", \"module.backbone.stages.2.2.conv3.weight\", \"module.backbone.stages.2.2.conv3.bias\", \"module.backbone.stages.2.2.conv3.gain\", \"module.backbone.stages.2.2.attn_last.conv.weight\", \"module.backbone.stages.2.3.conv1.weight\", \"module.backbone.stages.2.3.conv1.bias\", \"module.backbone.stages.2.3.conv1.gain\", \"module.backbone.stages.2.3.conv2.weight\", \"module.backbone.stages.2.3.conv2.bias\", \"module.backbone.stages.2.3.conv2.gain\", \"module.backbone.stages.2.3.conv2b.weight\", \"module.backbone.stages.2.3.conv2b.bias\", \"module.backbone.stages.2.3.conv2b.gain\", \"module.backbone.stages.2.3.conv3.weight\", \"module.backbone.stages.2.3.conv3.bias\", \"module.backbone.stages.2.3.conv3.gain\", \"module.backbone.stages.2.3.attn_last.conv.weight\", \"module.backbone.stages.2.4.conv1.weight\", \"module.backbone.stages.2.4.conv1.bias\", \"module.backbone.stages.2.4.conv1.gain\", \"module.backbone.stages.2.4.conv2.weight\", \"module.backbone.stages.2.4.conv2.bias\", \"module.backbone.stages.2.4.conv2.gain\", \"module.backbone.stages.2.4.conv2b.weight\", \"module.backbone.stages.2.4.conv2b.bias\", \"module.backbone.stages.2.4.conv2b.gain\", \"module.backbone.stages.2.4.conv3.weight\", \"module.backbone.stages.2.4.conv3.bias\", \"module.backbone.stages.2.4.conv3.gain\", \"module.backbone.stages.2.4.attn_last.conv.weight\", \"module.backbone.stages.2.5.conv1.weight\", \"module.backbone.stages.2.5.conv1.bias\", \"module.backbone.stages.2.5.conv1.gain\", \"module.backbone.stages.2.5.conv2.weight\", \"module.backbone.stages.2.5.conv2.bias\", \"module.backbone.stages.2.5.conv2.gain\", \"module.backbone.stages.2.5.conv2b.weight\", \"module.backbone.stages.2.5.conv2b.bias\", \"module.backbone.stages.2.5.conv2b.gain\", \"module.backbone.stages.2.5.conv3.weight\", \"module.backbone.stages.2.5.conv3.bias\", \"module.backbone.stages.2.5.conv3.gain\", \"module.backbone.stages.2.5.attn_last.conv.weight\", \"module.backbone.stages.3.0.downsample.conv.weight\", \"module.backbone.stages.3.0.downsample.conv.bias\", \"module.backbone.stages.3.0.downsample.conv.gain\", \"module.backbone.stages.3.0.conv1.weight\", \"module.backbone.stages.3.0.conv1.bias\", \"module.backbone.stages.3.0.conv1.gain\", \"module.backbone.stages.3.0.conv2.weight\", \"module.backbone.stages.3.0.conv2.bias\", \"module.backbone.stages.3.0.conv2.gain\", \"module.backbone.stages.3.0.conv2b.weight\", \"module.backbone.stages.3.0.conv2b.bias\", \"module.backbone.stages.3.0.conv2b.gain\", \"module.backbone.stages.3.0.conv3.weight\", \"module.backbone.stages.3.0.conv3.bias\", \"module.backbone.stages.3.0.conv3.gain\", \"module.backbone.stages.3.0.attn_last.conv.weight\", \"module.backbone.stages.3.1.conv1.weight\", \"module.backbone.stages.3.1.conv1.bias\", \"module.backbone.stages.3.1.conv1.gain\", \"module.backbone.stages.3.1.conv2.weight\", \"module.backbone.stages.3.1.conv2.bias\", \"module.backbone.stages.3.1.conv2.gain\", \"module.backbone.stages.3.1.conv2b.weight\", \"module.backbone.stages.3.1.conv2b.bias\", \"module.backbone.stages.3.1.conv2b.gain\", \"module.backbone.stages.3.1.conv3.weight\", \"module.backbone.stages.3.1.conv3.bias\", \"module.backbone.stages.3.1.conv3.gain\", \"module.backbone.stages.3.1.attn_last.conv.weight\", \"module.backbone.stages.3.2.conv1.weight\", \"module.backbone.stages.3.2.conv1.bias\", \"module.backbone.stages.3.2.conv1.gain\", \"module.backbone.stages.3.2.conv2.weight\", \"module.backbone.stages.3.2.conv2.bias\", \"module.backbone.stages.3.2.conv2.gain\", \"module.backbone.stages.3.2.conv2b.weight\", \"module.backbone.stages.3.2.conv2b.bias\", \"module.backbone.stages.3.2.conv2b.gain\", \"module.backbone.stages.3.2.conv3.weight\", \"module.backbone.stages.3.2.conv3.bias\", \"module.backbone.stages.3.2.conv3.gain\", \"module.backbone.stages.3.2.attn_last.conv.weight\", \"module.backbone.final_conv.weight\", \"module.backbone.final_conv.bias\", \"module.backbone.final_conv.gain\", \"module.global_pool.p\", \"module.head.weight\", \"module.head.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"stem.conv1.weight\", \"stem.conv1.bias\", \"stem.conv1.gain\", \"stem.conv2.weight\", \"stem.conv2.bias\", \"stem.conv2.gain\", \"stem.conv3.weight\", \"stem.conv3.bias\", \"stem.conv3.gain\", \"stem.conv4.weight\", \"stem.conv4.bias\", \"stem.conv4.gain\", \"stages.0.0.downsample.conv.weight\", \"stages.0.0.downsample.conv.bias\", \"stages.0.0.downsample.conv.gain\", \"stages.0.0.conv1.weight\", \"stages.0.0.conv1.bias\", \"stages.0.0.conv1.gain\", \"stages.0.0.conv2.weight\", \"stages.0.0.conv2.bias\", \"stages.0.0.conv2.gain\", \"stages.0.0.conv2b.weight\", \"stages.0.0.conv2b.bias\", \"stages.0.0.conv2b.gain\", \"stages.0.0.conv3.weight\", \"stages.0.0.conv3.bias\", \"stages.0.0.conv3.gain\", \"stages.0.0.attn_last.conv.weight\", \"stages.1.0.downsample.conv.weight\", \"stages.1.0.downsample.conv.bias\", \"stages.1.0.downsample.conv.gain\", \"stages.1.0.conv1.weight\", \"stages.1.0.conv1.bias\", \"stages.1.0.conv1.gain\", \"stages.1.0.conv2.weight\", \"stages.1.0.conv2.bias\", \"stages.1.0.conv2.gain\", \"stages.1.0.conv2b.weight\", \"stages.1.0.conv2b.bias\", \"stages.1.0.conv2b.gain\", \"stages.1.0.conv3.weight\", \"stages.1.0.conv3.bias\", \"stages.1.0.conv3.gain\", \"stages.1.0.attn_last.conv.weight\", \"stages.1.1.conv1.weight\", \"stages.1.1.conv1.bias\", \"stages.1.1.conv1.gain\", \"stages.1.1.conv2.weight\", \"stages.1.1.conv2.bias\", \"stages.1.1.conv2.gain\", \"stages.1.1.conv2b.weight\", \"stages.1.1.conv2b.bias\", \"stages.1.1.conv2b.gain\", \"stages.1.1.conv3.weight\", \"stages.1.1.conv3.bias\", \"stages.1.1.conv3.gain\", \"stages.1.1.attn_last.conv.weight\", \"stages.2.0.downsample.conv.weight\", \"stages.2.0.downsample.conv.bias\", \"stages.2.0.downsample.conv.gain\", \"stages.2.0.conv1.weight\", \"stages.2.0.conv1.bias\", \"stages.2.0.conv1.gain\", \"stages.2.0.conv2.weight\", \"stages.2.0.conv2.bias\", \"stages.2.0.conv2.gain\", \"stages.2.0.conv2b.weight\", \"stages.2.0.conv2b.bias\", \"stages.2.0.conv2b.gain\", \"stages.2.0.conv3.weight\", \"stages.2.0.conv3.bias\", \"stages.2.0.conv3.gain\", \"stages.2.0.attn_last.conv.weight\", \"stages.2.1.conv1.weight\", \"stages.2.1.conv1.bias\", \"stages.2.1.conv1.gain\", \"stages.2.1.conv2.weight\", \"stages.2.1.conv2.bias\", \"stages.2.1.conv2.gain\", \"stages.2.1.conv2b.weight\", \"stages.2.1.conv2b.bias\", \"stages.2.1.conv2b.gain\", \"stages.2.1.conv3.weight\", \"stages.2.1.conv3.bias\", \"stages.2.1.conv3.gain\", \"stages.2.1.attn_last.conv.weight\", \"stages.2.2.conv1.weight\", \"stages.2.2.conv1.bias\", \"stages.2.2.conv1.gain\", \"stages.2.2.conv2.weight\", \"stages.2.2.conv2.bias\", \"stages.2.2.conv2.gain\", \"stages.2.2.conv2b.weight\", \"stages.2.2.conv2b.bias\", \"stages.2.2.conv2b.gain\", \"stages.2.2.conv3.weight\", \"stages.2.2.conv3.bias\", \"stages.2.2.conv3.gain\", \"stages.2.2.attn_last.conv.weight\", \"stages.2.3.conv1.weight\", \"stages.2.3.conv1.bias\", \"stages.2.3.conv1.gain\", \"stages.2.3.conv2.weight\", \"stages.2.3.conv2.bias\", \"stages.2.3.conv2.gain\", \"stages.2.3.conv2b.weight\", \"stages.2.3.conv2b.bias\", \"stages.2.3.conv2b.gain\", \"stages.2.3.conv3.weight\", \"stages.2.3.conv3.bias\", \"stages.2.3.conv3.gain\", \"stages.2.3.attn_last.conv.weight\", \"stages.2.4.conv1.weight\", \"stages.2.4.conv1.bias\", \"stages.2.4.conv1.gain\", \"stages.2.4.conv2.weight\", \"stages.2.4.conv2.bias\", \"stages.2.4.conv2.gain\", \"stages.2.4.conv2b.weight\", \"stages.2.4.conv2b.bias\", \"stages.2.4.conv2b.gain\", \"stages.2.4.conv3.weight\", \"stages.2.4.conv3.bias\", \"stages.2.4.conv3.gain\", \"stages.2.4.attn_last.conv.weight\", \"stages.2.5.conv1.weight\", \"stages.2.5.conv1.bias\", \"stages.2.5.conv1.gain\", \"stages.2.5.conv2.weight\", \"stages.2.5.conv2.bias\", \"stages.2.5.conv2.gain\", \"stages.2.5.conv2b.weight\", \"stages.2.5.conv2b.bias\", \"stages.2.5.conv2b.gain\", \"stages.2.5.conv3.weight\", \"stages.2.5.conv3.bias\", \"stages.2.5.conv3.gain\", \"stages.2.5.attn_last.conv.weight\", \"stages.3.0.downsample.conv.weight\", \"stages.3.0.downsample.conv.bias\", \"stages.3.0.downsample.conv.gain\", \"stages.3.0.conv1.weight\", \"stages.3.0.conv1.bias\", \"stages.3.0.conv1.gain\", \"stages.3.0.conv2.weight\", \"stages.3.0.conv2.bias\", \"stages.3.0.conv2.gain\", \"stages.3.0.conv2b.weight\", \"stages.3.0.conv2b.bias\", \"stages.3.0.conv2b.gain\", \"stages.3.0.conv3.weight\", \"stages.3.0.conv3.bias\", \"stages.3.0.conv3.gain\", \"stages.3.0.attn_last.conv.weight\", \"stages.3.1.conv1.weight\", \"stages.3.1.conv1.bias\", \"stages.3.1.conv1.gain\", \"stages.3.1.conv2.weight\", \"stages.3.1.conv2.bias\", \"stages.3.1.conv2.gain\", \"stages.3.1.conv2b.weight\", \"stages.3.1.conv2b.bias\", \"stages.3.1.conv2b.gain\", \"stages.3.1.conv3.weight\", \"stages.3.1.conv3.bias\", \"stages.3.1.conv3.gain\", \"stages.3.1.attn_last.conv.weight\", \"stages.3.2.conv1.weight\", \"stages.3.2.conv1.bias\", \"stages.3.2.conv1.gain\", \"stages.3.2.conv2.weight\", \"stages.3.2.conv2.bias\", \"stages.3.2.conv2.gain\", \"stages.3.2.conv2b.weight\", \"stages.3.2.conv2b.bias\", \"stages.3.2.conv2b.gain\", \"stages.3.2.conv3.weight\", \"stages.3.2.conv3.bias\", \"stages.3.2.conv3.gain\", \"stages.3.2.attn_last.conv.weight\", \"final_conv.weight\", \"final_conv.bias\", \"final_conv.gain\". \n",
      "\n",
      "\n",
      " => current model:  TimmClassifier\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth'\n",
      "odict_keys(['stem.conv1.weight', 'stem.conv1.bias', 'stem.conv1.gain', 'stem.conv2.weight', 'stem.conv2.bias', 'stem.conv2.gain', 'stem.conv3.weight', 'stem.conv3.bias', 'stem.conv3.gain', 'stem.conv4.weight', 'stem.conv4.bias', 'stem.conv4.gain', 'stages.0.0.downsample.conv.weight', 'stages.0.0.downsample.conv.bias', 'stages.0.0.downsample.conv.gain', 'stages.0.0.conv1.weight', 'stages.0.0.conv1.bias', 'stages.0.0.conv1.gain', 'stages.0.0.conv2.weight', 'stages.0.0.conv2.bias', 'stages.0.0.conv2.gain', 'stages.0.0.conv2b.weight', 'stages.0.0.conv2b.bias', 'stages.0.0.conv2b.gain', 'stages.0.0.conv3.weight', 'stages.0.0.conv3.bias', 'stages.0.0.conv3.gain', 'stages.0.0.attn_last.conv.weight', 'stages.1.0.downsample.conv.weight', 'stages.1.0.downsample.conv.bias', 'stages.1.0.downsample.conv.gain', 'stages.1.0.conv1.weight', 'stages.1.0.conv1.bias', 'stages.1.0.conv1.gain', 'stages.1.0.conv2.weight', 'stages.1.0.conv2.bias', 'stages.1.0.conv2.gain', 'stages.1.0.conv2b.weight', 'stages.1.0.conv2b.bias', 'stages.1.0.conv2b.gain', 'stages.1.0.conv3.weight', 'stages.1.0.conv3.bias', 'stages.1.0.conv3.gain', 'stages.1.0.attn_last.conv.weight', 'stages.1.1.conv1.weight', 'stages.1.1.conv1.bias', 'stages.1.1.conv1.gain', 'stages.1.1.conv2.weight', 'stages.1.1.conv2.bias', 'stages.1.1.conv2.gain', 'stages.1.1.conv2b.weight', 'stages.1.1.conv2b.bias', 'stages.1.1.conv2b.gain', 'stages.1.1.conv3.weight', 'stages.1.1.conv3.bias', 'stages.1.1.conv3.gain', 'stages.1.1.attn_last.conv.weight', 'stages.2.0.downsample.conv.weight', 'stages.2.0.downsample.conv.bias', 'stages.2.0.downsample.conv.gain', 'stages.2.0.conv1.weight', 'stages.2.0.conv1.bias', 'stages.2.0.conv1.gain', 'stages.2.0.conv2.weight', 'stages.2.0.conv2.bias', 'stages.2.0.conv2.gain', 'stages.2.0.conv2b.weight', 'stages.2.0.conv2b.bias', 'stages.2.0.conv2b.gain', 'stages.2.0.conv3.weight', 'stages.2.0.conv3.bias', 'stages.2.0.conv3.gain', 'stages.2.0.attn_last.conv.weight', 'stages.2.1.conv1.weight', 'stages.2.1.conv1.bias', 'stages.2.1.conv1.gain', 'stages.2.1.conv2.weight', 'stages.2.1.conv2.bias', 'stages.2.1.conv2.gain', 'stages.2.1.conv2b.weight', 'stages.2.1.conv2b.bias', 'stages.2.1.conv2b.gain', 'stages.2.1.conv3.weight', 'stages.2.1.conv3.bias', 'stages.2.1.conv3.gain', 'stages.2.1.attn_last.conv.weight', 'stages.2.2.conv1.weight', 'stages.2.2.conv1.bias', 'stages.2.2.conv1.gain', 'stages.2.2.conv2.weight', 'stages.2.2.conv2.bias', 'stages.2.2.conv2.gain', 'stages.2.2.conv2b.weight', 'stages.2.2.conv2b.bias', 'stages.2.2.conv2b.gain', 'stages.2.2.conv3.weight', 'stages.2.2.conv3.bias', 'stages.2.2.conv3.gain', 'stages.2.2.attn_last.conv.weight', 'stages.2.3.conv1.weight', 'stages.2.3.conv1.bias', 'stages.2.3.conv1.gain', 'stages.2.3.conv2.weight', 'stages.2.3.conv2.bias', 'stages.2.3.conv2.gain', 'stages.2.3.conv2b.weight', 'stages.2.3.conv2b.bias', 'stages.2.3.conv2b.gain', 'stages.2.3.conv3.weight', 'stages.2.3.conv3.bias', 'stages.2.3.conv3.gain', 'stages.2.3.attn_last.conv.weight', 'stages.2.4.conv1.weight', 'stages.2.4.conv1.bias', 'stages.2.4.conv1.gain', 'stages.2.4.conv2.weight', 'stages.2.4.conv2.bias', 'stages.2.4.conv2.gain', 'stages.2.4.conv2b.weight', 'stages.2.4.conv2b.bias', 'stages.2.4.conv2b.gain', 'stages.2.4.conv3.weight', 'stages.2.4.conv3.bias', 'stages.2.4.conv3.gain', 'stages.2.4.attn_last.conv.weight', 'stages.2.5.conv1.weight', 'stages.2.5.conv1.bias', 'stages.2.5.conv1.gain', 'stages.2.5.conv2.weight', 'stages.2.5.conv2.bias', 'stages.2.5.conv2.gain', 'stages.2.5.conv2b.weight', 'stages.2.5.conv2b.bias', 'stages.2.5.conv2b.gain', 'stages.2.5.conv3.weight', 'stages.2.5.conv3.bias', 'stages.2.5.conv3.gain', 'stages.2.5.attn_last.conv.weight', 'stages.3.0.downsample.conv.weight', 'stages.3.0.downsample.conv.bias', 'stages.3.0.downsample.conv.gain', 'stages.3.0.conv1.weight', 'stages.3.0.conv1.bias', 'stages.3.0.conv1.gain', 'stages.3.0.conv2.weight', 'stages.3.0.conv2.bias', 'stages.3.0.conv2.gain', 'stages.3.0.conv2b.weight', 'stages.3.0.conv2b.bias', 'stages.3.0.conv2b.gain', 'stages.3.0.conv3.weight', 'stages.3.0.conv3.bias', 'stages.3.0.conv3.gain', 'stages.3.0.attn_last.conv.weight', 'stages.3.1.conv1.weight', 'stages.3.1.conv1.bias', 'stages.3.1.conv1.gain', 'stages.3.1.conv2.weight', 'stages.3.1.conv2.bias', 'stages.3.1.conv2.gain', 'stages.3.1.conv2b.weight', 'stages.3.1.conv2b.bias', 'stages.3.1.conv2b.gain', 'stages.3.1.conv3.weight', 'stages.3.1.conv3.bias', 'stages.3.1.conv3.gain', 'stages.3.1.attn_last.conv.weight', 'stages.3.2.conv1.weight', 'stages.3.2.conv1.bias', 'stages.3.2.conv1.gain', 'stages.3.2.conv2.weight', 'stages.3.2.conv2.bias', 'stages.3.2.conv2.gain', 'stages.3.2.conv2b.weight', 'stages.3.2.conv2b.bias', 'stages.3.2.conv2b.gain', 'stages.3.2.conv3.weight', 'stages.3.2.conv3.bias', 'stages.3.2.conv3.gain', 'stages.3.2.attn_last.conv.weight', 'final_conv.weight', 'final_conv.bias', 'final_conv.gain'])\n",
      "model not found Error(s) in loading state_dict for DataParallel:\n",
      "\tMissing key(s) in state_dict: \"module.mel_spec.spectrogram.window\", \"module.mel_spec.mel_scale.fb\", \"module.wav2img.0.spectrogram.window\", \"module.wav2img.0.mel_scale.fb\", \"module.encoder.stem.conv1.weight\", \"module.encoder.stem.conv1.bias\", \"module.encoder.stem.conv1.gain\", \"module.encoder.stem.conv2.weight\", \"module.encoder.stem.conv2.bias\", \"module.encoder.stem.conv2.gain\", \"module.encoder.stem.conv3.weight\", \"module.encoder.stem.conv3.bias\", \"module.encoder.stem.conv3.gain\", \"module.encoder.stem.conv4.weight\", \"module.encoder.stem.conv4.bias\", \"module.encoder.stem.conv4.gain\", \"module.encoder.stages.0.0.downsample.conv.weight\", \"module.encoder.stages.0.0.downsample.conv.bias\", \"module.encoder.stages.0.0.downsample.conv.gain\", \"module.encoder.stages.0.0.conv1.weight\", \"module.encoder.stages.0.0.conv1.bias\", \"module.encoder.stages.0.0.conv1.gain\", \"module.encoder.stages.0.0.conv2.weight\", \"module.encoder.stages.0.0.conv2.bias\", \"module.encoder.stages.0.0.conv2.gain\", \"module.encoder.stages.0.0.conv2b.weight\", \"module.encoder.stages.0.0.conv2b.bias\", \"module.encoder.stages.0.0.conv2b.gain\", \"module.encoder.stages.0.0.conv3.weight\", \"module.encoder.stages.0.0.conv3.bias\", \"module.encoder.stages.0.0.conv3.gain\", \"module.encoder.stages.0.0.attn_last.conv.weight\", \"module.encoder.stages.1.0.downsample.conv.weight\", \"module.encoder.stages.1.0.downsample.conv.bias\", \"module.encoder.stages.1.0.downsample.conv.gain\", \"module.encoder.stages.1.0.conv1.weight\", \"module.encoder.stages.1.0.conv1.bias\", \"module.encoder.stages.1.0.conv1.gain\", \"module.encoder.stages.1.0.conv2.weight\", \"module.encoder.stages.1.0.conv2.bias\", \"module.encoder.stages.1.0.conv2.gain\", \"module.encoder.stages.1.0.conv2b.weight\", \"module.encoder.stages.1.0.conv2b.bias\", \"module.encoder.stages.1.0.conv2b.gain\", \"module.encoder.stages.1.0.conv3.weight\", \"module.encoder.stages.1.0.conv3.bias\", \"module.encoder.stages.1.0.conv3.gain\", \"module.encoder.stages.1.0.attn_last.conv.weight\", \"module.encoder.stages.1.1.conv1.weight\", \"module.encoder.stages.1.1.conv1.bias\", \"module.encoder.stages.1.1.conv1.gain\", \"module.encoder.stages.1.1.conv2.weight\", \"module.encoder.stages.1.1.conv2.bias\", \"module.encoder.stages.1.1.conv2.gain\", \"module.encoder.stages.1.1.conv2b.weight\", \"module.encoder.stages.1.1.conv2b.bias\", \"module.encoder.stages.1.1.conv2b.gain\", \"module.encoder.stages.1.1.conv3.weight\", \"module.encoder.stages.1.1.conv3.bias\", \"module.encoder.stages.1.1.conv3.gain\", \"module.encoder.stages.1.1.attn_last.conv.weight\", \"module.encoder.stages.2.0.downsample.conv.weight\", \"module.encoder.stages.2.0.downsample.conv.bias\", \"module.encoder.stages.2.0.downsample.conv.gain\", \"module.encoder.stages.2.0.conv1.weight\", \"module.encoder.stages.2.0.conv1.bias\", \"module.encoder.stages.2.0.conv1.gain\", \"module.encoder.stages.2.0.conv2.weight\", \"module.encoder.stages.2.0.conv2.bias\", \"module.encoder.stages.2.0.conv2.gain\", \"module.encoder.stages.2.0.conv2b.weight\", \"module.encoder.stages.2.0.conv2b.bias\", \"module.encoder.stages.2.0.conv2b.gain\", \"module.encoder.stages.2.0.conv3.weight\", \"module.encoder.stages.2.0.conv3.bias\", \"module.encoder.stages.2.0.conv3.gain\", \"module.encoder.stages.2.0.attn_last.conv.weight\", \"module.encoder.stages.2.1.conv1.weight\", \"module.encoder.stages.2.1.conv1.bias\", \"module.encoder.stages.2.1.conv1.gain\", \"module.encoder.stages.2.1.conv2.weight\", \"module.encoder.stages.2.1.conv2.bias\", \"module.encoder.stages.2.1.conv2.gain\", \"module.encoder.stages.2.1.conv2b.weight\", \"module.encoder.stages.2.1.conv2b.bias\", \"module.encoder.stages.2.1.conv2b.gain\", \"module.encoder.stages.2.1.conv3.weight\", \"module.encoder.stages.2.1.conv3.bias\", \"module.encoder.stages.2.1.conv3.gain\", \"module.encoder.stages.2.1.attn_last.conv.weight\", \"module.encoder.stages.2.2.conv1.weight\", \"module.encoder.stages.2.2.conv1.bias\", \"module.encoder.stages.2.2.conv1.gain\", \"module.encoder.stages.2.2.conv2.weight\", \"module.encoder.stages.2.2.conv2.bias\", \"module.encoder.stages.2.2.conv2.gain\", \"module.encoder.stages.2.2.conv2b.weight\", \"module.encoder.stages.2.2.conv2b.bias\", \"module.encoder.stages.2.2.conv2b.gain\", \"module.encoder.stages.2.2.conv3.weight\", \"module.encoder.stages.2.2.conv3.bias\", \"module.encoder.stages.2.2.conv3.gain\", \"module.encoder.stages.2.2.attn_last.conv.weight\", \"module.encoder.stages.2.3.conv1.weight\", \"module.encoder.stages.2.3.conv1.bias\", \"module.encoder.stages.2.3.conv1.gain\", \"module.encoder.stages.2.3.conv2.weight\", \"module.encoder.stages.2.3.conv2.bias\", \"module.encoder.stages.2.3.conv2.gain\", \"module.encoder.stages.2.3.conv2b.weight\", \"module.encoder.stages.2.3.conv2b.bias\", \"module.encoder.stages.2.3.conv2b.gain\", \"module.encoder.stages.2.3.conv3.weight\", \"module.encoder.stages.2.3.conv3.bias\", \"module.encoder.stages.2.3.conv3.gain\", \"module.encoder.stages.2.3.attn_last.conv.weight\", \"module.encoder.stages.2.4.conv1.weight\", \"module.encoder.stages.2.4.conv1.bias\", \"module.encoder.stages.2.4.conv1.gain\", \"module.encoder.stages.2.4.conv2.weight\", \"module.encoder.stages.2.4.conv2.bias\", \"module.encoder.stages.2.4.conv2.gain\", \"module.encoder.stages.2.4.conv2b.weight\", \"module.encoder.stages.2.4.conv2b.bias\", \"module.encoder.stages.2.4.conv2b.gain\", \"module.encoder.stages.2.4.conv3.weight\", \"module.encoder.stages.2.4.conv3.bias\", \"module.encoder.stages.2.4.conv3.gain\", \"module.encoder.stages.2.4.attn_last.conv.weight\", \"module.encoder.stages.2.5.conv1.weight\", \"module.encoder.stages.2.5.conv1.bias\", \"module.encoder.stages.2.5.conv1.gain\", \"module.encoder.stages.2.5.conv2.weight\", \"module.encoder.stages.2.5.conv2.bias\", \"module.encoder.stages.2.5.conv2.gain\", \"module.encoder.stages.2.5.conv2b.weight\", \"module.encoder.stages.2.5.conv2b.bias\", \"module.encoder.stages.2.5.conv2b.gain\", \"module.encoder.stages.2.5.conv3.weight\", \"module.encoder.stages.2.5.conv3.bias\", \"module.encoder.stages.2.5.conv3.gain\", \"module.encoder.stages.2.5.attn_last.conv.weight\", \"module.encoder.stages.3.0.downsample.conv.weight\", \"module.encoder.stages.3.0.downsample.conv.bias\", \"module.encoder.stages.3.0.downsample.conv.gain\", \"module.encoder.stages.3.0.conv1.weight\", \"module.encoder.stages.3.0.conv1.bias\", \"module.encoder.stages.3.0.conv1.gain\", \"module.encoder.stages.3.0.conv2.weight\", \"module.encoder.stages.3.0.conv2.bias\", \"module.encoder.stages.3.0.conv2.gain\", \"module.encoder.stages.3.0.conv2b.weight\", \"module.encoder.stages.3.0.conv2b.bias\", \"module.encoder.stages.3.0.conv2b.gain\", \"module.encoder.stages.3.0.conv3.weight\", \"module.encoder.stages.3.0.conv3.bias\", \"module.encoder.stages.3.0.conv3.gain\", \"module.encoder.stages.3.0.attn_last.conv.weight\", \"module.encoder.stages.3.1.conv1.weight\", \"module.encoder.stages.3.1.conv1.bias\", \"module.encoder.stages.3.1.conv1.gain\", \"module.encoder.stages.3.1.conv2.weight\", \"module.encoder.stages.3.1.conv2.bias\", \"module.encoder.stages.3.1.conv2.gain\", \"module.encoder.stages.3.1.conv2b.weight\", \"module.encoder.stages.3.1.conv2b.bias\", \"module.encoder.stages.3.1.conv2b.gain\", \"module.encoder.stages.3.1.conv3.weight\", \"module.encoder.stages.3.1.conv3.bias\", \"module.encoder.stages.3.1.conv3.gain\", \"module.encoder.stages.3.1.attn_last.conv.weight\", \"module.encoder.stages.3.2.conv1.weight\", \"module.encoder.stages.3.2.conv1.bias\", \"module.encoder.stages.3.2.conv1.gain\", \"module.encoder.stages.3.2.conv2.weight\", \"module.encoder.stages.3.2.conv2.bias\", \"module.encoder.stages.3.2.conv2.gain\", \"module.encoder.stages.3.2.conv2b.weight\", \"module.encoder.stages.3.2.conv2b.bias\", \"module.encoder.stages.3.2.conv2b.gain\", \"module.encoder.stages.3.2.conv3.weight\", \"module.encoder.stages.3.2.conv3.bias\", \"module.encoder.stages.3.2.conv3.gain\", \"module.encoder.stages.3.2.attn_last.conv.weight\", \"module.encoder.final_conv.weight\", \"module.encoder.final_conv.bias\", \"module.encoder.final_conv.gain\", \"module.gem.p\", \"module.head1.weight\", \"module.head1.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"stem.conv1.weight\", \"stem.conv1.bias\", \"stem.conv1.gain\", \"stem.conv2.weight\", \"stem.conv2.bias\", \"stem.conv2.gain\", \"stem.conv3.weight\", \"stem.conv3.bias\", \"stem.conv3.gain\", \"stem.conv4.weight\", \"stem.conv4.bias\", \"stem.conv4.gain\", \"stages.0.0.downsample.conv.weight\", \"stages.0.0.downsample.conv.bias\", \"stages.0.0.downsample.conv.gain\", \"stages.0.0.conv1.weight\", \"stages.0.0.conv1.bias\", \"stages.0.0.conv1.gain\", \"stages.0.0.conv2.weight\", \"stages.0.0.conv2.bias\", \"stages.0.0.conv2.gain\", \"stages.0.0.conv2b.weight\", \"stages.0.0.conv2b.bias\", \"stages.0.0.conv2b.gain\", \"stages.0.0.conv3.weight\", \"stages.0.0.conv3.bias\", \"stages.0.0.conv3.gain\", \"stages.0.0.attn_last.conv.weight\", \"stages.1.0.downsample.conv.weight\", \"stages.1.0.downsample.conv.bias\", \"stages.1.0.downsample.conv.gain\", \"stages.1.0.conv1.weight\", \"stages.1.0.conv1.bias\", \"stages.1.0.conv1.gain\", \"stages.1.0.conv2.weight\", \"stages.1.0.conv2.bias\", \"stages.1.0.conv2.gain\", \"stages.1.0.conv2b.weight\", \"stages.1.0.conv2b.bias\", \"stages.1.0.conv2b.gain\", \"stages.1.0.conv3.weight\", \"stages.1.0.conv3.bias\", \"stages.1.0.conv3.gain\", \"stages.1.0.attn_last.conv.weight\", \"stages.1.1.conv1.weight\", \"stages.1.1.conv1.bias\", \"stages.1.1.conv1.gain\", \"stages.1.1.conv2.weight\", \"stages.1.1.conv2.bias\", \"stages.1.1.conv2.gain\", \"stages.1.1.conv2b.weight\", \"stages.1.1.conv2b.bias\", \"stages.1.1.conv2b.gain\", \"stages.1.1.conv3.weight\", \"stages.1.1.conv3.bias\", \"stages.1.1.conv3.gain\", \"stages.1.1.attn_last.conv.weight\", \"stages.2.0.downsample.conv.weight\", \"stages.2.0.downsample.conv.bias\", \"stages.2.0.downsample.conv.gain\", \"stages.2.0.conv1.weight\", \"stages.2.0.conv1.bias\", \"stages.2.0.conv1.gain\", \"stages.2.0.conv2.weight\", \"stages.2.0.conv2.bias\", \"stages.2.0.conv2.gain\", \"stages.2.0.conv2b.weight\", \"stages.2.0.conv2b.bias\", \"stages.2.0.conv2b.gain\", \"stages.2.0.conv3.weight\", \"stages.2.0.conv3.bias\", \"stages.2.0.conv3.gain\", \"stages.2.0.attn_last.conv.weight\", \"stages.2.1.conv1.weight\", \"stages.2.1.conv1.bias\", \"stages.2.1.conv1.gain\", \"stages.2.1.conv2.weight\", \"stages.2.1.conv2.bias\", \"stages.2.1.conv2.gain\", \"stages.2.1.conv2b.weight\", \"stages.2.1.conv2b.bias\", \"stages.2.1.conv2b.gain\", \"stages.2.1.conv3.weight\", \"stages.2.1.conv3.bias\", \"stages.2.1.conv3.gain\", \"stages.2.1.attn_last.conv.weight\", \"stages.2.2.conv1.weight\", \"stages.2.2.conv1.bias\", \"stages.2.2.conv1.gain\", \"stages.2.2.conv2.weight\", \"stages.2.2.conv2.bias\", \"stages.2.2.conv2.gain\", \"stages.2.2.conv2b.weight\", \"stages.2.2.conv2b.bias\", \"stages.2.2.conv2b.gain\", \"stages.2.2.conv3.weight\", \"stages.2.2.conv3.bias\", \"stages.2.2.conv3.gain\", \"stages.2.2.attn_last.conv.weight\", \"stages.2.3.conv1.weight\", \"stages.2.3.conv1.bias\", \"stages.2.3.conv1.gain\", \"stages.2.3.conv2.weight\", \"stages.2.3.conv2.bias\", \"stages.2.3.conv2.gain\", \"stages.2.3.conv2b.weight\", \"stages.2.3.conv2b.bias\", \"stages.2.3.conv2b.gain\", \"stages.2.3.conv3.weight\", \"stages.2.3.conv3.bias\", \"stages.2.3.conv3.gain\", \"stages.2.3.attn_last.conv.weight\", \"stages.2.4.conv1.weight\", \"stages.2.4.conv1.bias\", \"stages.2.4.conv1.gain\", \"stages.2.4.conv2.weight\", \"stages.2.4.conv2.bias\", \"stages.2.4.conv2.gain\", \"stages.2.4.conv2b.weight\", \"stages.2.4.conv2b.bias\", \"stages.2.4.conv2b.gain\", \"stages.2.4.conv3.weight\", \"stages.2.4.conv3.bias\", \"stages.2.4.conv3.gain\", \"stages.2.4.attn_last.conv.weight\", \"stages.2.5.conv1.weight\", \"stages.2.5.conv1.bias\", \"stages.2.5.conv1.gain\", \"stages.2.5.conv2.weight\", \"stages.2.5.conv2.bias\", \"stages.2.5.conv2.gain\", \"stages.2.5.conv2b.weight\", \"stages.2.5.conv2b.bias\", \"stages.2.5.conv2b.gain\", \"stages.2.5.conv3.weight\", \"stages.2.5.conv3.bias\", \"stages.2.5.conv3.gain\", \"stages.2.5.attn_last.conv.weight\", \"stages.3.0.downsample.conv.weight\", \"stages.3.0.downsample.conv.bias\", \"stages.3.0.downsample.conv.gain\", \"stages.3.0.conv1.weight\", \"stages.3.0.conv1.bias\", \"stages.3.0.conv1.gain\", \"stages.3.0.conv2.weight\", \"stages.3.0.conv2.bias\", \"stages.3.0.conv2.gain\", \"stages.3.0.conv2b.weight\", \"stages.3.0.conv2b.bias\", \"stages.3.0.conv2b.gain\", \"stages.3.0.conv3.weight\", \"stages.3.0.conv3.bias\", \"stages.3.0.conv3.gain\", \"stages.3.0.attn_last.conv.weight\", \"stages.3.1.conv1.weight\", \"stages.3.1.conv1.bias\", \"stages.3.1.conv1.gain\", \"stages.3.1.conv2.weight\", \"stages.3.1.conv2.bias\", \"stages.3.1.conv2.gain\", \"stages.3.1.conv2b.weight\", \"stages.3.1.conv2b.bias\", \"stages.3.1.conv2b.gain\", \"stages.3.1.conv3.weight\", \"stages.3.1.conv3.bias\", \"stages.3.1.conv3.gain\", \"stages.3.1.attn_last.conv.weight\", \"stages.3.2.conv1.weight\", \"stages.3.2.conv1.bias\", \"stages.3.2.conv1.gain\", \"stages.3.2.conv2.weight\", \"stages.3.2.conv2.bias\", \"stages.3.2.conv2.gain\", \"stages.3.2.conv2b.weight\", \"stages.3.2.conv2b.bias\", \"stages.3.2.conv2b.gain\", \"stages.3.2.conv3.weight\", \"stages.3.2.conv3.bias\", \"stages.3.2.conv3.gain\", \"stages.3.2.attn_last.conv.weight\", \"final_conv.weight\", \"final_conv.bias\", \"final_conv.gain\". \n",
      "\n",
      "\n",
      " => current model:  SEDTrainableFFT\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "STFT kernels created, time used = 0.0108 seconds\n",
      "model not found NormFreeNet.__init__() got an unexpected keyword argument 'duration'\n",
      "\n",
      "\n",
      " => current model:  C1C2\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing SED model...\n",
      "model not found NormFreeNet.__init__() got an unexpected keyword argument 'duration'\n",
      "\n",
      "\n",
      " => current model:  TimmClassifierSplitCrop_v1\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth'\n",
      "odict_keys(['stem.conv1.weight', 'stem.conv1.bias', 'stem.conv1.gain', 'stem.conv2.weight', 'stem.conv2.bias', 'stem.conv2.gain', 'stem.conv3.weight', 'stem.conv3.bias', 'stem.conv3.gain', 'stem.conv4.weight', 'stem.conv4.bias', 'stem.conv4.gain', 'stages.0.0.downsample.conv.weight', 'stages.0.0.downsample.conv.bias', 'stages.0.0.downsample.conv.gain', 'stages.0.0.conv1.weight', 'stages.0.0.conv1.bias', 'stages.0.0.conv1.gain', 'stages.0.0.conv2.weight', 'stages.0.0.conv2.bias', 'stages.0.0.conv2.gain', 'stages.0.0.conv2b.weight', 'stages.0.0.conv2b.bias', 'stages.0.0.conv2b.gain', 'stages.0.0.conv3.weight', 'stages.0.0.conv3.bias', 'stages.0.0.conv3.gain', 'stages.0.0.attn_last.conv.weight', 'stages.1.0.downsample.conv.weight', 'stages.1.0.downsample.conv.bias', 'stages.1.0.downsample.conv.gain', 'stages.1.0.conv1.weight', 'stages.1.0.conv1.bias', 'stages.1.0.conv1.gain', 'stages.1.0.conv2.weight', 'stages.1.0.conv2.bias', 'stages.1.0.conv2.gain', 'stages.1.0.conv2b.weight', 'stages.1.0.conv2b.bias', 'stages.1.0.conv2b.gain', 'stages.1.0.conv3.weight', 'stages.1.0.conv3.bias', 'stages.1.0.conv3.gain', 'stages.1.0.attn_last.conv.weight', 'stages.1.1.conv1.weight', 'stages.1.1.conv1.bias', 'stages.1.1.conv1.gain', 'stages.1.1.conv2.weight', 'stages.1.1.conv2.bias', 'stages.1.1.conv2.gain', 'stages.1.1.conv2b.weight', 'stages.1.1.conv2b.bias', 'stages.1.1.conv2b.gain', 'stages.1.1.conv3.weight', 'stages.1.1.conv3.bias', 'stages.1.1.conv3.gain', 'stages.1.1.attn_last.conv.weight', 'stages.2.0.downsample.conv.weight', 'stages.2.0.downsample.conv.bias', 'stages.2.0.downsample.conv.gain', 'stages.2.0.conv1.weight', 'stages.2.0.conv1.bias', 'stages.2.0.conv1.gain', 'stages.2.0.conv2.weight', 'stages.2.0.conv2.bias', 'stages.2.0.conv2.gain', 'stages.2.0.conv2b.weight', 'stages.2.0.conv2b.bias', 'stages.2.0.conv2b.gain', 'stages.2.0.conv3.weight', 'stages.2.0.conv3.bias', 'stages.2.0.conv3.gain', 'stages.2.0.attn_last.conv.weight', 'stages.2.1.conv1.weight', 'stages.2.1.conv1.bias', 'stages.2.1.conv1.gain', 'stages.2.1.conv2.weight', 'stages.2.1.conv2.bias', 'stages.2.1.conv2.gain', 'stages.2.1.conv2b.weight', 'stages.2.1.conv2b.bias', 'stages.2.1.conv2b.gain', 'stages.2.1.conv3.weight', 'stages.2.1.conv3.bias', 'stages.2.1.conv3.gain', 'stages.2.1.attn_last.conv.weight', 'stages.2.2.conv1.weight', 'stages.2.2.conv1.bias', 'stages.2.2.conv1.gain', 'stages.2.2.conv2.weight', 'stages.2.2.conv2.bias', 'stages.2.2.conv2.gain', 'stages.2.2.conv2b.weight', 'stages.2.2.conv2b.bias', 'stages.2.2.conv2b.gain', 'stages.2.2.conv3.weight', 'stages.2.2.conv3.bias', 'stages.2.2.conv3.gain', 'stages.2.2.attn_last.conv.weight', 'stages.2.3.conv1.weight', 'stages.2.3.conv1.bias', 'stages.2.3.conv1.gain', 'stages.2.3.conv2.weight', 'stages.2.3.conv2.bias', 'stages.2.3.conv2.gain', 'stages.2.3.conv2b.weight', 'stages.2.3.conv2b.bias', 'stages.2.3.conv2b.gain', 'stages.2.3.conv3.weight', 'stages.2.3.conv3.bias', 'stages.2.3.conv3.gain', 'stages.2.3.attn_last.conv.weight', 'stages.2.4.conv1.weight', 'stages.2.4.conv1.bias', 'stages.2.4.conv1.gain', 'stages.2.4.conv2.weight', 'stages.2.4.conv2.bias', 'stages.2.4.conv2.gain', 'stages.2.4.conv2b.weight', 'stages.2.4.conv2b.bias', 'stages.2.4.conv2b.gain', 'stages.2.4.conv3.weight', 'stages.2.4.conv3.bias', 'stages.2.4.conv3.gain', 'stages.2.4.attn_last.conv.weight', 'stages.2.5.conv1.weight', 'stages.2.5.conv1.bias', 'stages.2.5.conv1.gain', 'stages.2.5.conv2.weight', 'stages.2.5.conv2.bias', 'stages.2.5.conv2.gain', 'stages.2.5.conv2b.weight', 'stages.2.5.conv2b.bias', 'stages.2.5.conv2b.gain', 'stages.2.5.conv3.weight', 'stages.2.5.conv3.bias', 'stages.2.5.conv3.gain', 'stages.2.5.attn_last.conv.weight', 'stages.3.0.downsample.conv.weight', 'stages.3.0.downsample.conv.bias', 'stages.3.0.downsample.conv.gain', 'stages.3.0.conv1.weight', 'stages.3.0.conv1.bias', 'stages.3.0.conv1.gain', 'stages.3.0.conv2.weight', 'stages.3.0.conv2.bias', 'stages.3.0.conv2.gain', 'stages.3.0.conv2b.weight', 'stages.3.0.conv2b.bias', 'stages.3.0.conv2b.gain', 'stages.3.0.conv3.weight', 'stages.3.0.conv3.bias', 'stages.3.0.conv3.gain', 'stages.3.0.attn_last.conv.weight', 'stages.3.1.conv1.weight', 'stages.3.1.conv1.bias', 'stages.3.1.conv1.gain', 'stages.3.1.conv2.weight', 'stages.3.1.conv2.bias', 'stages.3.1.conv2.gain', 'stages.3.1.conv2b.weight', 'stages.3.1.conv2b.bias', 'stages.3.1.conv2b.gain', 'stages.3.1.conv3.weight', 'stages.3.1.conv3.bias', 'stages.3.1.conv3.gain', 'stages.3.1.attn_last.conv.weight', 'stages.3.2.conv1.weight', 'stages.3.2.conv1.bias', 'stages.3.2.conv1.gain', 'stages.3.2.conv2.weight', 'stages.3.2.conv2.bias', 'stages.3.2.conv2.gain', 'stages.3.2.conv2b.weight', 'stages.3.2.conv2b.bias', 'stages.3.2.conv2b.gain', 'stages.3.2.conv3.weight', 'stages.3.2.conv3.bias', 'stages.3.2.conv3.gain', 'stages.3.2.attn_last.conv.weight', 'final_conv.weight', 'final_conv.bias', 'final_conv.gain'])\n",
      "model not found Error(s) in loading state_dict for DataParallel:\n",
      "\tMissing key(s) in state_dict: \"module.mel_spec.spectrogram.window\", \"module.mel_spec.mel_scale.fb\", \"module.wav2img.0.spectrogram.window\", \"module.wav2img.0.mel_scale.fb\", \"module.encoder.stem_conv1.weight\", \"module.encoder.stem_conv1.bias\", \"module.encoder.stem_conv1.gain\", \"module.encoder.stem_conv2.weight\", \"module.encoder.stem_conv2.bias\", \"module.encoder.stem_conv2.gain\", \"module.encoder.stem_conv3.weight\", \"module.encoder.stem_conv3.bias\", \"module.encoder.stem_conv3.gain\", \"module.encoder.stem_conv4.weight\", \"module.encoder.stem_conv4.bias\", \"module.encoder.stem_conv4.gain\", \"module.encoder.stages_0.0.downsample.conv.weight\", \"module.encoder.stages_0.0.downsample.conv.bias\", \"module.encoder.stages_0.0.downsample.conv.gain\", \"module.encoder.stages_0.0.conv1.weight\", \"module.encoder.stages_0.0.conv1.bias\", \"module.encoder.stages_0.0.conv1.gain\", \"module.encoder.stages_0.0.conv2.weight\", \"module.encoder.stages_0.0.conv2.bias\", \"module.encoder.stages_0.0.conv2.gain\", \"module.encoder.stages_0.0.conv2b.weight\", \"module.encoder.stages_0.0.conv2b.bias\", \"module.encoder.stages_0.0.conv2b.gain\", \"module.encoder.stages_0.0.conv3.weight\", \"module.encoder.stages_0.0.conv3.bias\", \"module.encoder.stages_0.0.conv3.gain\", \"module.encoder.stages_0.0.attn_last.conv.weight\", \"module.encoder.stages_1.0.downsample.conv.weight\", \"module.encoder.stages_1.0.downsample.conv.bias\", \"module.encoder.stages_1.0.downsample.conv.gain\", \"module.encoder.stages_1.0.conv1.weight\", \"module.encoder.stages_1.0.conv1.bias\", \"module.encoder.stages_1.0.conv1.gain\", \"module.encoder.stages_1.0.conv2.weight\", \"module.encoder.stages_1.0.conv2.bias\", \"module.encoder.stages_1.0.conv2.gain\", \"module.encoder.stages_1.0.conv2b.weight\", \"module.encoder.stages_1.0.conv2b.bias\", \"module.encoder.stages_1.0.conv2b.gain\", \"module.encoder.stages_1.0.conv3.weight\", \"module.encoder.stages_1.0.conv3.bias\", \"module.encoder.stages_1.0.conv3.gain\", \"module.encoder.stages_1.0.attn_last.conv.weight\", \"module.encoder.stages_1.1.conv1.weight\", \"module.encoder.stages_1.1.conv1.bias\", \"module.encoder.stages_1.1.conv1.gain\", \"module.encoder.stages_1.1.conv2.weight\", \"module.encoder.stages_1.1.conv2.bias\", \"module.encoder.stages_1.1.conv2.gain\", \"module.encoder.stages_1.1.conv2b.weight\", \"module.encoder.stages_1.1.conv2b.bias\", \"module.encoder.stages_1.1.conv2b.gain\", \"module.encoder.stages_1.1.conv3.weight\", \"module.encoder.stages_1.1.conv3.bias\", \"module.encoder.stages_1.1.conv3.gain\", \"module.encoder.stages_1.1.attn_last.conv.weight\", \"module.encoder.stages_2.0.downsample.conv.weight\", \"module.encoder.stages_2.0.downsample.conv.bias\", \"module.encoder.stages_2.0.downsample.conv.gain\", \"module.encoder.stages_2.0.conv1.weight\", \"module.encoder.stages_2.0.conv1.bias\", \"module.encoder.stages_2.0.conv1.gain\", \"module.encoder.stages_2.0.conv2.weight\", \"module.encoder.stages_2.0.conv2.bias\", \"module.encoder.stages_2.0.conv2.gain\", \"module.encoder.stages_2.0.conv2b.weight\", \"module.encoder.stages_2.0.conv2b.bias\", \"module.encoder.stages_2.0.conv2b.gain\", \"module.encoder.stages_2.0.conv3.weight\", \"module.encoder.stages_2.0.conv3.bias\", \"module.encoder.stages_2.0.conv3.gain\", \"module.encoder.stages_2.0.attn_last.conv.weight\", \"module.encoder.stages_2.1.conv1.weight\", \"module.encoder.stages_2.1.conv1.bias\", \"module.encoder.stages_2.1.conv1.gain\", \"module.encoder.stages_2.1.conv2.weight\", \"module.encoder.stages_2.1.conv2.bias\", \"module.encoder.stages_2.1.conv2.gain\", \"module.encoder.stages_2.1.conv2b.weight\", \"module.encoder.stages_2.1.conv2b.bias\", \"module.encoder.stages_2.1.conv2b.gain\", \"module.encoder.stages_2.1.conv3.weight\", \"module.encoder.stages_2.1.conv3.bias\", \"module.encoder.stages_2.1.conv3.gain\", \"module.encoder.stages_2.1.attn_last.conv.weight\", \"module.encoder.stages_2.2.conv1.weight\", \"module.encoder.stages_2.2.conv1.bias\", \"module.encoder.stages_2.2.conv1.gain\", \"module.encoder.stages_2.2.conv2.weight\", \"module.encoder.stages_2.2.conv2.bias\", \"module.encoder.stages_2.2.conv2.gain\", \"module.encoder.stages_2.2.conv2b.weight\", \"module.encoder.stages_2.2.conv2b.bias\", \"module.encoder.stages_2.2.conv2b.gain\", \"module.encoder.stages_2.2.conv3.weight\", \"module.encoder.stages_2.2.conv3.bias\", \"module.encoder.stages_2.2.conv3.gain\", \"module.encoder.stages_2.2.attn_last.conv.weight\", \"module.encoder.stages_2.3.conv1.weight\", \"module.encoder.stages_2.3.conv1.bias\", \"module.encoder.stages_2.3.conv1.gain\", \"module.encoder.stages_2.3.conv2.weight\", \"module.encoder.stages_2.3.conv2.bias\", \"module.encoder.stages_2.3.conv2.gain\", \"module.encoder.stages_2.3.conv2b.weight\", \"module.encoder.stages_2.3.conv2b.bias\", \"module.encoder.stages_2.3.conv2b.gain\", \"module.encoder.stages_2.3.conv3.weight\", \"module.encoder.stages_2.3.conv3.bias\", \"module.encoder.stages_2.3.conv3.gain\", \"module.encoder.stages_2.3.attn_last.conv.weight\", \"module.encoder.stages_2.4.conv1.weight\", \"module.encoder.stages_2.4.conv1.bias\", \"module.encoder.stages_2.4.conv1.gain\", \"module.encoder.stages_2.4.conv2.weight\", \"module.encoder.stages_2.4.conv2.bias\", \"module.encoder.stages_2.4.conv2.gain\", \"module.encoder.stages_2.4.conv2b.weight\", \"module.encoder.stages_2.4.conv2b.bias\", \"module.encoder.stages_2.4.conv2b.gain\", \"module.encoder.stages_2.4.conv3.weight\", \"module.encoder.stages_2.4.conv3.bias\", \"module.encoder.stages_2.4.conv3.gain\", \"module.encoder.stages_2.4.attn_last.conv.weight\", \"module.encoder.stages_2.5.conv1.weight\", \"module.encoder.stages_2.5.conv1.bias\", \"module.encoder.stages_2.5.conv1.gain\", \"module.encoder.stages_2.5.conv2.weight\", \"module.encoder.stages_2.5.conv2.bias\", \"module.encoder.stages_2.5.conv2.gain\", \"module.encoder.stages_2.5.conv2b.weight\", \"module.encoder.stages_2.5.conv2b.bias\", \"module.encoder.stages_2.5.conv2b.gain\", \"module.encoder.stages_2.5.conv3.weight\", \"module.encoder.stages_2.5.conv3.bias\", \"module.encoder.stages_2.5.conv3.gain\", \"module.encoder.stages_2.5.attn_last.conv.weight\", \"module.encoder.stages_3.0.downsample.conv.weight\", \"module.encoder.stages_3.0.downsample.conv.bias\", \"module.encoder.stages_3.0.downsample.conv.gain\", \"module.encoder.stages_3.0.conv1.weight\", \"module.encoder.stages_3.0.conv1.bias\", \"module.encoder.stages_3.0.conv1.gain\", \"module.encoder.stages_3.0.conv2.weight\", \"module.encoder.stages_3.0.conv2.bias\", \"module.encoder.stages_3.0.conv2.gain\", \"module.encoder.stages_3.0.conv2b.weight\", \"module.encoder.stages_3.0.conv2b.bias\", \"module.encoder.stages_3.0.conv2b.gain\", \"module.encoder.stages_3.0.conv3.weight\", \"module.encoder.stages_3.0.conv3.bias\", \"module.encoder.stages_3.0.conv3.gain\", \"module.encoder.stages_3.0.attn_last.conv.weight\", \"module.encoder.stages_3.1.conv1.weight\", \"module.encoder.stages_3.1.conv1.bias\", \"module.encoder.stages_3.1.conv1.gain\", \"module.encoder.stages_3.1.conv2.weight\", \"module.encoder.stages_3.1.conv2.bias\", \"module.encoder.stages_3.1.conv2.gain\", \"module.encoder.stages_3.1.conv2b.weight\", \"module.encoder.stages_3.1.conv2b.bias\", \"module.encoder.stages_3.1.conv2b.gain\", \"module.encoder.stages_3.1.conv3.weight\", \"module.encoder.stages_3.1.conv3.bias\", \"module.encoder.stages_3.1.conv3.gain\", \"module.encoder.stages_3.1.attn_last.conv.weight\", \"module.encoder.stages_3.2.conv1.weight\", \"module.encoder.stages_3.2.conv1.bias\", \"module.encoder.stages_3.2.conv1.gain\", \"module.encoder.stages_3.2.conv2.weight\", \"module.encoder.stages_3.2.conv2.bias\", \"module.encoder.stages_3.2.conv2.gain\", \"module.encoder.stages_3.2.conv2b.weight\", \"module.encoder.stages_3.2.conv2b.bias\", \"module.encoder.stages_3.2.conv2b.gain\", \"module.encoder.stages_3.2.conv3.weight\", \"module.encoder.stages_3.2.conv3.bias\", \"module.encoder.stages_3.2.conv3.gain\", \"module.encoder.stages_3.2.attn_last.conv.weight\", \"module.encoder.final_conv.weight\", \"module.encoder.final_conv.bias\", \"module.encoder.final_conv.gain\", \"module.gem.p\", \"module.head1.weight\", \"module.head1.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"stem.conv1.weight\", \"stem.conv1.bias\", \"stem.conv1.gain\", \"stem.conv2.weight\", \"stem.conv2.bias\", \"stem.conv2.gain\", \"stem.conv3.weight\", \"stem.conv3.bias\", \"stem.conv3.gain\", \"stem.conv4.weight\", \"stem.conv4.bias\", \"stem.conv4.gain\", \"stages.0.0.downsample.conv.weight\", \"stages.0.0.downsample.conv.bias\", \"stages.0.0.downsample.conv.gain\", \"stages.0.0.conv1.weight\", \"stages.0.0.conv1.bias\", \"stages.0.0.conv1.gain\", \"stages.0.0.conv2.weight\", \"stages.0.0.conv2.bias\", \"stages.0.0.conv2.gain\", \"stages.0.0.conv2b.weight\", \"stages.0.0.conv2b.bias\", \"stages.0.0.conv2b.gain\", \"stages.0.0.conv3.weight\", \"stages.0.0.conv3.bias\", \"stages.0.0.conv3.gain\", \"stages.0.0.attn_last.conv.weight\", \"stages.1.0.downsample.conv.weight\", \"stages.1.0.downsample.conv.bias\", \"stages.1.0.downsample.conv.gain\", \"stages.1.0.conv1.weight\", \"stages.1.0.conv1.bias\", \"stages.1.0.conv1.gain\", \"stages.1.0.conv2.weight\", \"stages.1.0.conv2.bias\", \"stages.1.0.conv2.gain\", \"stages.1.0.conv2b.weight\", \"stages.1.0.conv2b.bias\", \"stages.1.0.conv2b.gain\", \"stages.1.0.conv3.weight\", \"stages.1.0.conv3.bias\", \"stages.1.0.conv3.gain\", \"stages.1.0.attn_last.conv.weight\", \"stages.1.1.conv1.weight\", \"stages.1.1.conv1.bias\", \"stages.1.1.conv1.gain\", \"stages.1.1.conv2.weight\", \"stages.1.1.conv2.bias\", \"stages.1.1.conv2.gain\", \"stages.1.1.conv2b.weight\", \"stages.1.1.conv2b.bias\", \"stages.1.1.conv2b.gain\", \"stages.1.1.conv3.weight\", \"stages.1.1.conv3.bias\", \"stages.1.1.conv3.gain\", \"stages.1.1.attn_last.conv.weight\", \"stages.2.0.downsample.conv.weight\", \"stages.2.0.downsample.conv.bias\", \"stages.2.0.downsample.conv.gain\", \"stages.2.0.conv1.weight\", \"stages.2.0.conv1.bias\", \"stages.2.0.conv1.gain\", \"stages.2.0.conv2.weight\", \"stages.2.0.conv2.bias\", \"stages.2.0.conv2.gain\", \"stages.2.0.conv2b.weight\", \"stages.2.0.conv2b.bias\", \"stages.2.0.conv2b.gain\", \"stages.2.0.conv3.weight\", \"stages.2.0.conv3.bias\", \"stages.2.0.conv3.gain\", \"stages.2.0.attn_last.conv.weight\", \"stages.2.1.conv1.weight\", \"stages.2.1.conv1.bias\", \"stages.2.1.conv1.gain\", \"stages.2.1.conv2.weight\", \"stages.2.1.conv2.bias\", \"stages.2.1.conv2.gain\", \"stages.2.1.conv2b.weight\", \"stages.2.1.conv2b.bias\", \"stages.2.1.conv2b.gain\", \"stages.2.1.conv3.weight\", \"stages.2.1.conv3.bias\", \"stages.2.1.conv3.gain\", \"stages.2.1.attn_last.conv.weight\", \"stages.2.2.conv1.weight\", \"stages.2.2.conv1.bias\", \"stages.2.2.conv1.gain\", \"stages.2.2.conv2.weight\", \"stages.2.2.conv2.bias\", \"stages.2.2.conv2.gain\", \"stages.2.2.conv2b.weight\", \"stages.2.2.conv2b.bias\", \"stages.2.2.conv2b.gain\", \"stages.2.2.conv3.weight\", \"stages.2.2.conv3.bias\", \"stages.2.2.conv3.gain\", \"stages.2.2.attn_last.conv.weight\", \"stages.2.3.conv1.weight\", \"stages.2.3.conv1.bias\", \"stages.2.3.conv1.gain\", \"stages.2.3.conv2.weight\", \"stages.2.3.conv2.bias\", \"stages.2.3.conv2.gain\", \"stages.2.3.conv2b.weight\", \"stages.2.3.conv2b.bias\", \"stages.2.3.conv2b.gain\", \"stages.2.3.conv3.weight\", \"stages.2.3.conv3.bias\", \"stages.2.3.conv3.gain\", \"stages.2.3.attn_last.conv.weight\", \"stages.2.4.conv1.weight\", \"stages.2.4.conv1.bias\", \"stages.2.4.conv1.gain\", \"stages.2.4.conv2.weight\", \"stages.2.4.conv2.bias\", \"stages.2.4.conv2.gain\", \"stages.2.4.conv2b.weight\", \"stages.2.4.conv2b.bias\", \"stages.2.4.conv2b.gain\", \"stages.2.4.conv3.weight\", \"stages.2.4.conv3.bias\", \"stages.2.4.conv3.gain\", \"stages.2.4.attn_last.conv.weight\", \"stages.2.5.conv1.weight\", \"stages.2.5.conv1.bias\", \"stages.2.5.conv1.gain\", \"stages.2.5.conv2.weight\", \"stages.2.5.conv2.bias\", \"stages.2.5.conv2.gain\", \"stages.2.5.conv2b.weight\", \"stages.2.5.conv2b.bias\", \"stages.2.5.conv2b.gain\", \"stages.2.5.conv3.weight\", \"stages.2.5.conv3.bias\", \"stages.2.5.conv3.gain\", \"stages.2.5.attn_last.conv.weight\", \"stages.3.0.downsample.conv.weight\", \"stages.3.0.downsample.conv.bias\", \"stages.3.0.downsample.conv.gain\", \"stages.3.0.conv1.weight\", \"stages.3.0.conv1.bias\", \"stages.3.0.conv1.gain\", \"stages.3.0.conv2.weight\", \"stages.3.0.conv2.bias\", \"stages.3.0.conv2.gain\", \"stages.3.0.conv2b.weight\", \"stages.3.0.conv2b.bias\", \"stages.3.0.conv2b.gain\", \"stages.3.0.conv3.weight\", \"stages.3.0.conv3.bias\", \"stages.3.0.conv3.gain\", \"stages.3.0.attn_last.conv.weight\", \"stages.3.1.conv1.weight\", \"stages.3.1.conv1.bias\", \"stages.3.1.conv1.gain\", \"stages.3.1.conv2.weight\", \"stages.3.1.conv2.bias\", \"stages.3.1.conv2.gain\", \"stages.3.1.conv2b.weight\", \"stages.3.1.conv2b.bias\", \"stages.3.1.conv2b.gain\", \"stages.3.1.conv3.weight\", \"stages.3.1.conv3.bias\", \"stages.3.1.conv3.gain\", \"stages.3.1.attn_last.conv.weight\", \"stages.3.2.conv1.weight\", \"stages.3.2.conv1.bias\", \"stages.3.2.conv1.gain\", \"stages.3.2.conv2.weight\", \"stages.3.2.conv2.bias\", \"stages.3.2.conv2.gain\", \"stages.3.2.conv2b.weight\", \"stages.3.2.conv2b.bias\", \"stages.3.2.conv2b.gain\", \"stages.3.2.conv3.weight\", \"stages.3.2.conv3.bias\", \"stages.3.2.conv3.gain\", \"stages.3.2.attn_last.conv.weight\", \"final_conv.weight\", \"final_conv.bias\", \"final_conv.gain\". \n",
      "\n",
      "=> best fit:   conflicts: 100000.0\n"
     ]
    }
   ],
   "source": [
    "model = load_model_v1(conf_path  = f\"{github_folder}/configs/cls_nf0_v5.json\",\n",
    "                               weights_path = f\"{github_folder}/weights\",\n",
    "                               prefix       = \"nf0_v5_\",\n",
    "                               suffix       = sx,\n",
    "                               fold         = i,\n",
    "                               is_test=True)\n",
    "# models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "## best only for now\n",
    "suffixes = [\"lb\"]#, \"f1_score\" \"last\"]\n",
    "folds    = 5\n",
    "\n",
    "for i in range(folds):\n",
    "    for sx in suffixes:\n",
    "        try:\n",
    "            model = load_model(conf_path    = f\"{github_folder}/configs/cls_nf0_v5.json\",\n",
    "                               weights_path = f\"{github_folder}/weights/nfnet-baseline-bs16\",\n",
    "                               prefix       = \"nf0_v5_\",\n",
    "                               suffix       = sx,\n",
    "                               fold         = i)\n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"model not found\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SED', 'TimmClassifier_v1', 'TimmClassifier_v2', 'TimmClassifier2021', 'TimmClassifier', 'SEDTrainableFFT', 'C1C2', 'TimmClassifierSplitCrop_v1']\n",
      "\n",
      "\n",
      " => current model:  SED\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing SED model...\n",
      "\n",
      "\n",
      " => current model:  TimmClassifier_v1\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth''\n",
      "\n",
      "\n",
      " => current model:  TimmClassifier_v2\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth''\n",
      "\n",
      "\n",
      " => current model:  TimmClassifier2021\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth''\n",
      "\n",
      "\n",
      " => current model:  TimmClassifier\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth''\n",
      "\n",
      "\n",
      " => current model:  SEDTrainableFFT\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "STFT kernels created, time used = 0.0112 seconds\n",
      "\n",
      "\n",
      " => current model:  C1C2\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing SED model...\n",
      "\n",
      "\n",
      " => current model:  TimmClassifierSplitCrop_v1\n",
      "./weights/pretrained_eca_nfnet_l0.pth\n",
      "initing CLS features model 15 duration...\n",
      "pretrained model...\n",
      "=> loading checkpoint './weights/pretrained_eca_nfnet_l0.pth''\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:36.917136Z",
     "iopub.status.busy": "2022-05-24T07:32:36.91621Z",
     "iopub.status.idle": "2022-05-24T07:32:36.937547Z",
     "shell.execute_reply": "2022-05-24T07:32:36.936615Z",
     "shell.execute_reply.started": "2022-05-24T07:32:36.917094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = \"abethr1 abhori1 abythr1 afbfly1 afdfly1 afecuc1 affeag1 afgfly1 afghor1 afmdov1 afpfly1 afpkin1 afpwag1 afrgos1 afrgrp1 afrjac1 afrthr1 amesun2 augbuz1 bagwea1 barswa bawhor2 bawman1 bcbeat1 beasun2 bkctch1 bkfruw1 blacra1 blacuc1 blakit1 blaplo1 blbpuf2 blcapa2 blfbus1 blhgon1 blhher1 blksaw1 blnmou1 blnwea1 bltapa1 bltbar1 bltori1 blwlap1 brcale1 brcsta1 brctch1 brcwea1 brican1 brobab1 broman1 brosun1 brrwhe3 brtcha1 brubru1 brwwar1 bswdov1 btweye2 bubwar2 butapa1 cabgre1 carcha1 carwoo1 categr ccbeat1 chespa1 chewea1 chibat1 chtapa3 chucis1 cibwar1 cohmar1 colsun2 combul2 combuz1 comsan crefra2 crheag1 crohor1 darbar1 darter3 didcuc1 dotbar1 dutdov1 easmog1 eaywag1 edcsun3 egygoo equaka1 eswdov1 eubeat1 fatrav1 fatwid1 fislov1 fotdro5 gabgos2 gargan gbesta1 gnbcam2 gnhsun1 gobbun1 gobsta5 gobwea1 golher1 grbcam1 grccra1 grecor greegr grewoo2 grwpyt1 gryapa1 grywrw1 gybfis1 gycwar3 gyhbus1 gyhkin1 gyhneg1 gyhspa1 gytbar1 hadibi1 hamerk1 hartur1 helgui hipbab1 hoopoe huncis1 hunsun2 joygre1 kerspa2 klacuc1 kvbsun1 laudov1 lawgol lesmaw1 lessts1 libeat1 litegr litswi1 litwea1 loceag1 lotcor1 lotlap1 luebus1 mabeat1 macshr1 malkin1 marsto1 marsun2 mcptit1 meypar1 moccha1 mouwag1 ndcsun2 nobfly1 norbro1 norcro1 norfis1 norpuf1 nubwoo1 pabspa1 palfly2 palpri1 piecro1 piekin1 pitwhy purgre2 pygbat1 quailf1 ratcis1 raybar1 rbsrob1 rebfir2 rebhor1 reboxp1 reccor reccuc1 reedov1 refbar2 refcro1 reftin1 refwar2 rehblu1 rehwea1 reisee2 rerswa1 rewsta1 rindov rocmar2 rostur1 ruegls1 rufcha2 sacibi2 sccsun2 scrcha1 scthon1 shesta1 sichor1 sincis1 slbgre1 slcbou1 sltnig1 sobfly1 somgre1 somtit4 soucit1 soufis1 spemou2 spepig1 spewea1 spfbar1 spfwea1 spmthr1 spwlap1 squher1 strher strsee1 stusta1 subbus1 supsta1 tacsun1 tafpri1 tamdov1 thrnig1 trobou1 varsun2 vibsta2 vilwea1 vimwea1 walsta1 wbgbir1 wbrcha2 wbswea1 wfbeat1 whbcan1 whbcou1 whbcro2 whbtit5 whbwea1 whbwhe3 whcpri2 whctur2 wheslf1 whhsaw1 whihel1 whrshr1 witswa1 wlwwar wookin1 woosan wtbeat1 yebapa1 yebbar1 yebduc1 yebere1 yebgre1 yebsto1 yeccan1 yefcan yelbis1 yenspu1 yertin1 yesbar1 yespet1 yetgre1 yewgre1\".split()\n",
    "N_CLASS = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:36.940932Z",
     "iopub.status.busy": "2022-05-24T07:32:36.940127Z",
     "iopub.status.idle": "2022-05-24T07:32:36.961547Z",
     "shell.execute_reply": "2022-05-24T07:32:36.960562Z",
     "shell.execute_reply.started": "2022-05-24T07:32:36.940888Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_clip(fpath, frame_length, sample_rate):\n",
    "    \"\"\"\n",
    "    Prepare audio clip for inference\n",
    "    \"\"\"\n",
    "    infer_frame_length = frame_length\n",
    "    batch = {\"wav_tensors\": [], \"end_times\": []}\n",
    "    \n",
    "    waveform, sample_rate = librosa.load(fpath, sr=sample_rate, mono=True)\n",
    "    n_parts = math.ceil(len(waveform) / int(infer_frame_length * sample_rate))\n",
    "    \n",
    "    for seg_idx in range(n_parts): \n",
    "        end_time = (seg_idx + 1) * frame_length\n",
    "        seg_wav  = waveform[(end_time*sample_rate)-(sample_rate*frame_length):end_time*sample_rate]\n",
    "        \n",
    "        wav_tensor = torch.from_numpy(seg_wav)\n",
    "        \n",
    "        if len(wav_tensor) == frame_length * sample_rate:\n",
    "            batch[\"wav_tensors\"].append(wav_tensor.unsqueeze(0))\n",
    "        elif len(wav_tensor) < frame_length * sample_rate:\n",
    "            wav_tensor = torch.nn.functional.pad(wav_tensor, (0, (frame_length * sample_rate) - len(wav_tensor)))\n",
    "            batch[\"wav_tensors\"].append(wav_tensor.unsqueeze(0))\n",
    "        elif len(wav_tensor) > frame_length * sample_rate:\n",
    "            wav_tensor = wav_tensor[:(frame_length * sample_rate)]\n",
    "            batch[\"wav_tensors\"].append(wav_tensor.unsqueeze(0))\n",
    "            \n",
    "        batch[\"end_times\"].append(end_time)\n",
    "    batch[\"wav_tensors\"] = torch.stack(batch[\"wav_tensors\"]).cuda()\n",
    "    return batch, n_parts, len(waveform)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_clip(models, batch, n_parts, frame_length):\n",
    "    preds = np.zeros([len(models), n_parts, N_CLASS])\n",
    "    for m_idx, model in enumerate(models):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds[m_idx] = model(batch[\"wav_tensors\"], is_test=True)[\"logit\"].sigmoid().cpu().numpy()\n",
    "    return preds.mean(0) ## max by model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:36.9649Z",
     "iopub.status.busy": "2022-05-24T07:32:36.963915Z",
     "iopub.status.idle": "2022-05-24T07:32:36.976477Z",
     "shell.execute_reply": "2022-05-24T07:32:36.975716Z",
     "shell.execute_reply.started": "2022-05-24T07:32:36.964859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:36.980232Z",
     "iopub.status.busy": "2022-05-24T07:32:36.978599Z",
     "iopub.status.idle": "2022-05-24T07:32:37.424085Z",
     "shell.execute_reply": "2022-05-24T07:32:37.423167Z",
     "shell.execute_reply.started": "2022-05-24T07:32:36.980114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test file num: 1\n",
      "CPU times: user 695 ms, sys: 11.8 ms, total: 707 ms\n",
      "Wall time: 705 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_preds():\n",
    "    debug = False\n",
    "    preds        = []\n",
    "    test_files   = sorted(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\")) \n",
    "    sample_rate  = 32000\n",
    "    \n",
    "    scored_birds = np.array(CLASSES)\n",
    "\n",
    "    frame_length = 5\n",
    "    infer_frame_length = 5\n",
    "\n",
    "    print(\"test file num:\", len(test_files))\n",
    "    for fpath in test_files:\n",
    "        file_id = os.path.basename(fpath).replace(\".ogg\", \"\")\n",
    "        batch, n_parts, len_waveform = prepare_clip(fpath, frame_length, sample_rate)\n",
    "        clip_preds = predict_clip(models, batch, n_parts, frame_length)\n",
    "        preds.append(clip_preds)\n",
    "        \n",
    "        ## switch to infer frame length\n",
    "        n_parts_sub = math.ceil(len_waveform / int(infer_frame_length * sample_rate))\n",
    "        clip_preds = np.array_split(clip_preds, n_parts_sub, axis=0)\n",
    "        \n",
    "                \n",
    "    prob_array = np.array(preds)\n",
    "    \n",
    "    scored_bird_name2idx = {}\n",
    "    for i, x in enumerate(scored_birds):\n",
    "        scored_bird_name2idx[x] = i\n",
    "\n",
    "    return prob_array, scored_bird_name2idx\n",
    "\n",
    "prob_array, scored_bird_name2idx = generate_preds()\n",
    "# del models\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:37.426326Z",
     "iopub.status.busy": "2022-05-24T07:32:37.425478Z",
     "iopub.status.idle": "2022-05-24T07:32:37.435498Z",
     "shell.execute_reply": "2022-05-24T07:32:37.434489Z",
     "shell.execute_reply.started": "2022-05-24T07:32:37.426281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120, 264)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:37.438021Z",
     "iopub.status.busy": "2022-05-24T07:32:37.437306Z",
     "iopub.status.idle": "2022-05-24T07:32:37.446866Z",
     "shell.execute_reply": "2022-05-24T07:32:37.445828Z",
     "shell.execute_reply.started": "2022-05-24T07:32:37.437961Z"
    }
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/input/birdnetgit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:37.449962Z",
     "iopub.status.busy": "2022-05-24T07:32:37.449191Z",
     "iopub.status.idle": "2022-05-24T07:32:37.493709Z",
     "shell.execute_reply": "2022-05-24T07:32:37.492807Z",
     "shell.execute_reply.started": "2022-05-24T07:32:37.449807Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import json\n",
    "# import math\n",
    "# import glob\n",
    "# import librosa\n",
    "# import operator\n",
    "# import argparse\n",
    "# import datetime\n",
    "# import traceback\n",
    "\n",
    "# from multiprocessing import Pool, freeze_support\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# import config as cfg\n",
    "# import audio\n",
    "# import model\n",
    "# from analyze import *\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:37.496216Z",
     "iopub.status.busy": "2022-05-24T07:32:37.49551Z",
     "iopub.status.idle": "2022-05-24T07:32:37.856202Z",
     "shell.execute_reply": "2022-05-24T07:32:37.855485Z",
     "shell.execute_reply.started": "2022-05-24T07:32:37.496087Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../birdclef-2022/eBird_Taxonomy_v2021.csv\")\n",
    "# s2id = lambda x: df[(df['PRIMARY_COM_NAME'] == x)].SPECIES_CODE.tolist()[0]\n",
    "\n",
    "# cfg.MODEL_PATH = '/kaggle/input/birdnetgit/checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_Model_FP32.tflite'\n",
    "# cfg.MDATA_MODEL_PATH = '/kaggle/input/birdnetgit/checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_MData_Model_FP32.tflite'\n",
    "# cfg.LABELS_FILE = '/kaggle/input/birdnetgit/checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_Labels.txt'\n",
    "# cfg.TRANSLATED_LABELS_PATH = '/kaggle/input/birdnetgit/labels/V2.1'\n",
    "\n",
    "# cfg.SIG_LENGTH = 5\n",
    "# cfg.SIG_OVERLAP = 0 \n",
    "# cfg.SIG_MINLEN = 5 \n",
    "\n",
    "# # Load eBird codes, labels\n",
    "\n",
    "# def loadCodes(CODEC_FILE):\n",
    "\n",
    "#     with open(CODEC_FILE, 'r') as cfile:\n",
    "#         codes = json.load(cfile)\n",
    "\n",
    "#     return codes\n",
    "\n",
    "# cfg.CODES = loadCodes(\"./eBird_taxonomy_codes_2021E.json\")\n",
    "# def loadLabels(labels_file):\n",
    "\n",
    "#     labels = []\n",
    "#     with open(labels_file, 'r') as lfile:\n",
    "#         for line in lfile.readlines():\n",
    "#             labels.append(line.replace('\\n', ''))    \n",
    "\n",
    "#     return labels\n",
    "\n",
    "# def prepare_clip(fpath):\n",
    "#     \"\"\"\n",
    "#     Prepare audio clip for inference\n",
    "#     \"\"\"\n",
    "#     sample_rate = cfg.SAMPLE_RATE\n",
    "#     frame_length = cfg.SIG_LENGTH\n",
    "#     infer_frame_length = frame_length\n",
    "    \n",
    "#     sample_rate = 48000\n",
    "#     chunks = []\n",
    "    \n",
    "#     waveform, sample_rate = librosa.load(fpath, sr=sample_rate, mono=True, res_type='kaiser_fast')\n",
    "#     n_parts = math.ceil(len(waveform) / int(infer_frame_length * sample_rate))\n",
    "    \n",
    "#     for seg_idx in range(n_parts): \n",
    "#         end_time = (seg_idx + 1) * frame_length\n",
    "#         chunk  = waveform[(end_time*sample_rate)-(sample_rate*frame_length):end_time*sample_rate]\n",
    "                \n",
    "#         if len(chunk) == frame_length * sample_rate:\n",
    "#             chunks.append(chunk)\n",
    "#         elif len(chunk) < frame_length * sample_rate:\n",
    "#             chunk = np.pad(chunk, (0, (frame_length * sample_rate) - len(chunk)))\n",
    "#             chunks.append(chunk)\n",
    "#         elif len(chunk) > frame_length * sample_rate:\n",
    "#             chunk = chunk[:(frame_length * sample_rate)]\n",
    "#             chunks.append(chunk)\n",
    "            \n",
    "#     return chunks\n",
    "\n",
    "\n",
    "# scored_birds = np.array(['akiapo', 'aniani', 'apapan', 'barpet', 'crehon', 'elepai', 'ercfra',\n",
    "#                           'hawama', 'hawcre', 'hawgoo', 'hawhaw', 'hawpet1', 'houfin', 'iiwi',\n",
    "#                           'jabwar', 'maupar', 'omao', 'puaioh', 'skylar', 'warwhe1', 'yefcan'])\n",
    "\n",
    "# cfg.LABELS = loadLabels(cfg.LABELS_FILE)\n",
    "\n",
    "# model.loadModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:37.859112Z",
     "iopub.status.busy": "2022-05-24T07:32:37.85836Z",
     "iopub.status.idle": "2022-05-24T07:32:44.386605Z",
     "shell.execute_reply": "2022-05-24T07:32:44.385561Z",
     "shell.execute_reply.started": "2022-05-24T07:32:37.859065Z"
    }
   },
   "outputs": [],
   "source": [
    "# bird_dict = {}\n",
    "# for i, lb in enumerate(cfg.LABELS):\n",
    "#     try:\n",
    "#         lbb = s2id(lb.split(\"_\")[-1])\n",
    "#         if lbb in scored_birds:\n",
    "#             bird_dict[lbb] = i\n",
    "#     except Exception as e:\n",
    "#         continue\n",
    "    \n",
    "# bird_dict[\"aniani\"] = 0\n",
    "\n",
    "# sorted_bd = dict(sorted(bird_dict.items(), key=lambda item: item[0]))\n",
    "# get_idx = list(sorted_bd.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:44.392119Z",
     "iopub.status.busy": "2022-05-24T07:32:44.391255Z",
     "iopub.status.idle": "2022-05-24T07:32:44.400116Z",
     "shell.execute_reply": "2022-05-24T07:32:44.399344Z",
     "shell.execute_reply.started": "2022-05-24T07:32:44.392073Z"
    }
   },
   "outputs": [],
   "source": [
    "# # def predict_single(test_path)\n",
    "\n",
    "# def generate_preds_bn():\n",
    "#     test_files   = sorted(glob.glob(\"/kaggle/input/birdclef-2022/test_soundscapes/*.ogg\"))\n",
    "    \n",
    "#     preds = []\n",
    "#     file_ids = []\n",
    "    \n",
    "#     for fpath in test_files:\n",
    "#         chunks = prepare_clip(fpath)\n",
    "#         pred = predict(chunks)[:, get_idx]\n",
    "#         preds.append(pred)\n",
    "#         file_id = os.path.basename(fpath).replace(\".ogg\", \"\")\n",
    "#         file_ids.append(file_id)\n",
    "        \n",
    "#     preds = np.array(preds)\n",
    "#     return preds, file_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:44.402843Z",
     "iopub.status.busy": "2022-05-24T07:32:44.402027Z",
     "iopub.status.idle": "2022-05-24T07:32:48.302119Z",
     "shell.execute_reply": "2022-05-24T07:32:48.301164Z",
     "shell.execute_reply.started": "2022-05-24T07:32:44.402789Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# preds_bn, file_ids = generate_preds_bn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:32:48.30447Z",
     "iopub.status.busy": "2022-05-24T07:32:48.303571Z",
     "iopub.status.idle": "2022-05-24T07:32:48.31003Z",
     "shell.execute_reply": "2022-05-24T07:32:48.308744Z",
     "shell.execute_reply.started": "2022-05-24T07:32:48.304429Z"
    }
   },
   "outputs": [],
   "source": [
    "# preds_bn[:, :, 1] = prob_array[:, :, 1] # 有一种鸟类缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_ids():\n",
    "    test_files   = sorted(glob.glob(\"/kaggle/input/birdclef-2022/test_soundscapes/*.ogg\"))\n",
    "    \n",
    "    file_ids = []\n",
    "    \n",
    "    for fpath in test_files:\n",
    "        file_id = os.path.basename(fpath).replace(\".ogg\", \"\")\n",
    "        file_ids.append(file_id)\n",
    "        \n",
    "    return file_ids\n",
    "\n",
    "file_ids = generate_file_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:33:55.262072Z",
     "iopub.status.busy": "2022-05-24T07:33:55.26178Z",
     "iopub.status.idle": "2022-05-24T07:33:55.268869Z",
     "shell.execute_reply": "2022-05-24T07:33:55.267989Z",
     "shell.execute_reply.started": "2022-05-24T07:33:55.262043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120, 264)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fix aniani\n",
    "avg_preds = prob_array\n",
    "\n",
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:48:12.292113Z",
     "iopub.status.busy": "2022-05-24T07:48:12.29143Z",
     "iopub.status.idle": "2022-05-24T07:48:12.300749Z",
     "shell.execute_reply": "2022-05-24T07:48:12.29853Z",
     "shell.execute_reply.started": "2022-05-24T07:48:12.292074Z"
    }
   },
   "outputs": [],
   "source": [
    "submission   = []\n",
    "infer_frame_length = 5\n",
    "threshold = 0.2\n",
    "\n",
    "for clip_preds, file_id in zip(avg_preds, file_ids):\n",
    "    for frame_idx, pred in enumerate(clip_preds):\n",
    "        end_time = (frame_idx + 1) * infer_frame_length\n",
    "        d = {\n",
    "            \"row_id\": f\"{file_id}_{end_time}\",\n",
    "            # \"target\": pred[bi] > threshold,\n",
    "        }\n",
    "        for bi, bird in enumerate(CLASSES):\n",
    "            d[bird] = pred[bi]\n",
    "        submission.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:48:12.457884Z",
     "iopub.status.busy": "2022-05-24T07:48:12.457092Z",
     "iopub.status.idle": "2022-05-24T07:48:12.465085Z",
     "shell.execute_reply": "2022-05-24T07:48:12.463594Z",
     "shell.execute_reply.started": "2022-05-24T07:48:12.457831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/kaggle/working'\n",
      "/home/mobius/code/kaggle/BLEF/rank1/birdclef-2022\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:48:12.641499Z",
     "iopub.status.busy": "2022-05-24T07:48:12.641186Z",
     "iopub.status.idle": "2022-05-24T07:48:12.653065Z",
     "shell.execute_reply": "2022-05-24T07:48:12.65214Z",
     "shell.execute_reply.started": "2022-05-24T07:48:12.641444Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(submission).set_index(\"row_id\")\n",
    "df_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T07:48:12.909956Z",
     "iopub.status.busy": "2022-05-24T07:48:12.909318Z",
     "iopub.status.idle": "2022-05-24T07:48:12.924891Z",
     "shell.execute_reply": "2022-05-24T07:48:12.92357Z",
     "shell.execute_reply.started": "2022-05-24T07:48:12.909915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>afmdov1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_5</th>\n",
       "      <td>0.126487</td>\n",
       "      <td>0.082135</td>\n",
       "      <td>0.080978</td>\n",
       "      <td>0.048578</td>\n",
       "      <td>0.050510</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>0.075433</td>\n",
       "      <td>0.024035</td>\n",
       "      <td>0.160303</td>\n",
       "      <td>0.053009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>0.017149</td>\n",
       "      <td>0.048940</td>\n",
       "      <td>0.027983</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.084363</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>0.054019</td>\n",
       "      <td>0.053470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_10</th>\n",
       "      <td>0.066574</td>\n",
       "      <td>0.164496</td>\n",
       "      <td>0.030779</td>\n",
       "      <td>0.066138</td>\n",
       "      <td>0.037714</td>\n",
       "      <td>0.032803</td>\n",
       "      <td>0.077673</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.144080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008452</td>\n",
       "      <td>0.019594</td>\n",
       "      <td>0.077687</td>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.048686</td>\n",
       "      <td>0.069257</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.027779</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_15</th>\n",
       "      <td>0.080323</td>\n",
       "      <td>0.081409</td>\n",
       "      <td>0.044128</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>0.057581</td>\n",
       "      <td>0.047525</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>0.037262</td>\n",
       "      <td>0.075879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.083878</td>\n",
       "      <td>0.041879</td>\n",
       "      <td>0.019554</td>\n",
       "      <td>0.062750</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.031625</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>0.034436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_20</th>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.054861</td>\n",
       "      <td>0.033537</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.038520</td>\n",
       "      <td>0.048108</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.055145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.051416</td>\n",
       "      <td>0.037178</td>\n",
       "      <td>0.045248</td>\n",
       "      <td>0.030559</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>0.048044</td>\n",
       "      <td>0.034192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_25</th>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.053903</td>\n",
       "      <td>0.038099</td>\n",
       "      <td>0.042058</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>0.035039</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.055972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.013768</td>\n",
       "      <td>0.044425</td>\n",
       "      <td>0.037059</td>\n",
       "      <td>0.028831</td>\n",
       "      <td>0.037836</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>0.029175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          abethr1   abhori1   abythr1   afbfly1   afdfly1  \\\n",
       "row_id                                                                      \n",
       "soundscape_453028782_5   0.126487  0.082135  0.080978  0.048578  0.050510   \n",
       "soundscape_453028782_10  0.066574  0.164496  0.030779  0.066138  0.037714   \n",
       "soundscape_453028782_15  0.080323  0.081409  0.044128  0.017276  0.023266   \n",
       "soundscape_453028782_20  0.032924  0.054861  0.033537  0.064783  0.026036   \n",
       "soundscape_453028782_25  0.032156  0.053903  0.038099  0.042058  0.025344   \n",
       "\n",
       "                          afecuc1   affeag1   afgfly1   afghor1   afmdov1  \\\n",
       "row_id                                                                      \n",
       "soundscape_453028782_5   0.101477  0.075433  0.024035  0.160303  0.053009   \n",
       "soundscape_453028782_10  0.032803  0.077673  0.018512  0.038596  0.144080   \n",
       "soundscape_453028782_15  0.057581  0.047525  0.018962  0.037262  0.075879   \n",
       "soundscape_453028782_20  0.041327  0.038520  0.048108  0.087000  0.055145   \n",
       "soundscape_453028782_25  0.041344  0.033179  0.035039  0.080115  0.055972   \n",
       "\n",
       "                         ...   yebsto1   yeccan1    yefcan   yelbis1  \\\n",
       "row_id                   ...                                           \n",
       "soundscape_453028782_5   ...  0.014767  0.017149  0.048940  0.027983   \n",
       "soundscape_453028782_10  ...  0.008452  0.019594  0.077687  0.045750   \n",
       "soundscape_453028782_15  ...  0.003203  0.015982  0.083878  0.041879   \n",
       "soundscape_453028782_20  ...  0.003781  0.016900  0.036923  0.051416   \n",
       "soundscape_453028782_25  ...  0.003029  0.013768  0.044425  0.037059   \n",
       "\n",
       "                          yenspu1   yertin1   yesbar1   yespet1   yetgre1  \\\n",
       "row_id                                                                      \n",
       "soundscape_453028782_5   0.046173  0.084363  0.033920  0.033705  0.054019   \n",
       "soundscape_453028782_10  0.048686  0.069257  0.020712  0.027779  0.021687   \n",
       "soundscape_453028782_15  0.019554  0.062750  0.014851  0.031625  0.027172   \n",
       "soundscape_453028782_20  0.037178  0.045248  0.030559  0.035767  0.048044   \n",
       "soundscape_453028782_25  0.028831  0.037836  0.025044  0.025127  0.041965   \n",
       "\n",
       "                          yewgre1  \n",
       "row_id                             \n",
       "soundscape_453028782_5   0.053470  \n",
       "soundscape_453028782_10  0.075800  \n",
       "soundscape_453028782_15  0.034436  \n",
       "soundscape_453028782_20  0.034192  \n",
       "soundscape_453028782_25  0.029175  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"\"\"\n",
    "# total rows : {len(df_submission)}\n",
    "# activated  : {len(df_submission[(df_submission.target==True)])}\n",
    "# \"\"\")\n",
    "\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
